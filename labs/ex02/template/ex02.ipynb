{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    error = y - tx @ w\n",
    "    MSE = 1 / (2 * N) * sum(error ** 2)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i, w0 in enumerate(grid_w0):\n",
    "        for j, w1 in enumerate(grid_w1):\n",
    "            loss = compute_loss(y, tx, np.array([w0, w1]))\n",
    "            losses[i, j] = loss\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=18.79354101952322, w0*=71.42857142857142, w1*=15.306122448979579, execution time=156.149 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=50)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    error = y - tx @ w\n",
    "    grad = - 1 / N * tx.T @ error\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.24318739722845"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_grad1 = compute_gradient(y, tx, np.array([100, 50]))\n",
    "norm1 = np.sqrt(sum(hand_grad1 ** 2))\n",
    "norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.552392678247728"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_grad2 = compute_gradient(y, tx, np.array([50, 10]))\n",
    "norm2 = np.sqrt(sum(hand_grad2 ** 2))\n",
    "norm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        # ***************************************************\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "        w = w - gamma * grad\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=378.04738819875917, w0=97.32939220021052, w1=10.347971243498908\n",
      "GD iter. 1/49: loss=309.14170313607127, w0=94.92584518039999, w1=10.661145362647924\n",
      "GD iter. 2/49: loss=253.32809823529604, w0=92.7626528625705, w1=10.943002069882038\n",
      "GD iter. 3/49: loss=208.11907826566784, w0=90.81577977652397, w1=11.19667310639274\n",
      "GD iter. 4/49: loss=171.49977209026855, w0=89.06359399908209, w1=11.424977039252374\n",
      "GD iter. 5/49: loss=141.8381340881947, w0=87.4866267993844, w1=11.630450578826043\n",
      "GD iter. 6/49: loss=117.81220730651565, w0=86.06735631965648, w1=11.815376764442345\n",
      "GD iter. 7/49: loss=98.35120661335488, w0=84.79001288790136, w1=11.981810331497016\n",
      "GD iter. 8/49: loss=82.58779605189532, w0=83.64040379932173, w1=12.13160054184622\n",
      "GD iter. 9/49: loss=69.81943349711283, w0=82.60575561960007, w1=12.266411731160504\n",
      "GD iter. 10/49: loss=59.4770598277387, w0=81.67457225785058, w1=12.38774180154336\n",
      "GD iter. 11/49: loss=51.09973715554607, w0=80.83650723227605, w1=12.49693886488793\n",
      "GD iter. 12/49: loss=44.31410579106989, w0=80.08224870925896, w1=12.595216221898044\n",
      "GD iter. 13/49: loss=38.81774438584418, w0=79.40341603854358, w1=12.683665843207145\n",
      "GD iter. 14/49: loss=34.36569164761137, w0=78.79246663489974, w1=12.763270502385335\n",
      "GD iter. 15/49: loss=30.759528929642677, w0=78.24261217162028, w1=12.834914695645708\n",
      "GD iter. 16/49: loss=27.83853712808816, w0=77.74774315466877, w1=12.899394469580042\n",
      "GD iter. 17/49: loss=25.472533768828995, w0=77.3023610394124, w1=12.957426266120942\n",
      "GD iter. 18/49: loss=23.55607104782902, w0=76.90151713568169, w1=13.009654883007753\n",
      "GD iter. 19/49: loss=22.00373624381911, w0=76.54075762232404, w1=13.056660638205884\n",
      "GD iter. 20/49: loss=20.74634505257106, w0=76.21607406030215, w1=13.098965817884201\n",
      "GD iter. 21/49: loss=19.727858187660203, w0=75.92385885448245, w1=13.137040479594686\n",
      "GD iter. 22/49: loss=18.90288382708233, w0=75.66086516924472, w1=13.171307675134123\n",
      "GD iter. 23/49: loss=18.234654595014266, w0=75.42417085253076, w1=13.202148151119616\n",
      "GD iter. 24/49: loss=17.693388917039222, w0=75.2111459674882, w1=13.22990457950656\n",
      "GD iter. 25/49: loss=17.25496371787924, w0=75.01942357094991, w1=13.25488536505481\n",
      "GD iter. 26/49: loss=16.899839306559848, w0=74.84687341406544, w1=13.277368072048233\n",
      "GD iter. 27/49: loss=16.612188533391084, w0=74.69157827286942, w1=13.297602508342315\n",
      "GD iter. 28/49: loss=16.37919140712429, w0=74.55181264579299, w1=13.31581350100699\n",
      "GD iter. 29/49: loss=16.190463734848283, w0=74.42602358142422, w1=13.332203394405195\n",
      "GD iter. 30/49: loss=16.03759432030469, w0=74.31281342349232, w1=13.34695429846358\n",
      "GD iter. 31/49: loss=15.91377009452445, w0=74.2109242813536, w1=13.360230112116126\n",
      "GD iter. 32/49: loss=15.813472471642426, w0=74.11922405342875, w1=13.372178344403418\n",
      "GD iter. 33/49: loss=15.732231397107785, w0=74.0366938482964, w1=13.38293175346198\n",
      "GD iter. 34/49: loss=15.666426126734924, w0=73.96241666367727, w1=13.392609821614688\n",
      "GD iter. 35/49: loss=15.613123857732846, w0=73.89556719752007, w1=13.401320082952124\n",
      "GD iter. 36/49: loss=15.569949019841303, w0=73.83540267797858, w1=13.409159318155815\n",
      "GD iter. 37/49: loss=15.534977401148977, w0=73.78125461039124, w1=13.41621462983914\n",
      "GD iter. 38/49: loss=15.506650390008273, w0=73.73252134956263, w1=13.42256441035413\n",
      "GD iter. 39/49: loss=15.483705510984297, w0=73.68866141481689, w1=13.428279212817623\n",
      "GD iter. 40/49: loss=15.465120158974896, w0=73.64918747354572, w1=13.433422535034765\n",
      "GD iter. 41/49: loss=15.450066023847189, w0=73.61366092640166, w1=13.438051525030193\n",
      "GD iter. 42/49: loss=15.437872174393933, w0=73.58168703397202, w1=13.44221761602608\n",
      "GD iter. 43/49: loss=15.427995156336664, w0=73.55291053078534, w1=13.445967097922376\n",
      "GD iter. 44/49: loss=15.419994771710213, w0=73.52701167791733, w1=13.449341631629043\n",
      "GD iter. 45/49: loss=15.413514460162919, w0=73.50370271033611, w1=13.452378711965043\n",
      "GD iter. 46/49: loss=15.408265407809488, w0=73.48272463951302, w1=13.455112084267444\n",
      "GD iter. 47/49: loss=15.404013675403325, w0=73.46384437577224, w1=13.457572119339606\n",
      "GD iter. 48/49: loss=15.400569772154263, w0=73.44685213840553, w1=13.45978615090455\n",
      "GD iter. 49/49: loss=15.397780210522514, w0=73.4315591247755, w1=13.461778779313\n",
      "GD: execution time=5.984 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([100, 10])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d7296b13384d5b81cfbce7bb84220d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helpers import batch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from just few examples n and their corresponding y_n labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    # ***************************************************\n",
    "    N = len(y)\n",
    "    error = y - tx @ w\n",
    "    grad = - 1 / N * tx.T @ error\n",
    "    return grad\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "        for batch_y, batch_tx in batch_iter(y, tx, batch_size):\n",
    "            grad = compute_gradient(batch_y, batch_tx, w)\n",
    "            loss = compute_loss(batch_y, batch_tx, w)\n",
    "        w = w - gamma * grad\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=3272.3504054775635, w0=8.089932515760022, w1=3.848135505443063\n",
      "SGD iter. 1/49: loss=3461.0037157221705, w0=16.409792749829066, w1=14.554397008515055\n",
      "SGD iter. 2/49: loss=1898.8255051940237, w0=22.57230117610164, w1=11.605206399812015\n",
      "SGD iter. 3/49: loss=1197.039352939786, w0=27.465233533982314, w1=10.000081765015947\n",
      "SGD iter. 4/49: loss=757.5082683703154, w0=31.35755486802018, w1=3.735012648164803\n",
      "SGD iter. 5/49: loss=1770.6718480945642, w0=37.30847386947628, w1=10.687913629923653\n",
      "SGD iter. 6/49: loss=973.3747601077847, w0=41.720672324006145, w1=15.502838682628695\n",
      "SGD iter. 7/49: loss=596.9298974499974, w0=45.17589995022702, w1=15.299995237619454\n",
      "SGD iter. 8/49: loss=246.57217273883342, w0=47.39658530722307, w1=18.231964113609823\n",
      "SGD iter. 9/49: loss=681.3850050060615, w0=51.08815680187426, w1=10.14241372165132\n",
      "SGD iter. 10/49: loss=352.58615023143483, w0=53.743664852065166, w1=13.08377306336551\n",
      "SGD iter. 11/49: loss=38.01289699911859, w0=54.6155925669489, w1=13.3890278904936\n",
      "SGD iter. 12/49: loss=160.59283806252878, w0=56.407757950291234, w1=12.178342932779923\n",
      "SGD iter. 13/49: loss=319.7566584255399, w0=58.936618003459614, w1=10.90962957750063\n",
      "SGD iter. 14/49: loss=21.954254038776877, w0=59.599252956337544, w1=10.391253036120727\n",
      "SGD iter. 15/49: loss=77.4803424619509, w0=60.84408501297772, w1=11.168224040221089\n",
      "SGD iter. 16/49: loss=77.17861485774277, w0=62.08649086339652, w1=11.005779045936478\n",
      "SGD iter. 17/49: loss=23.828866977128673, w0=62.77683667495952, w1=9.164385292601139\n",
      "SGD iter. 18/49: loss=41.509613899544235, w0=63.687985553020006, w1=9.709992290690177\n",
      "SGD iter. 19/49: loss=6.128524563981807, w0=64.03808624036529, w1=9.00290573590565\n",
      "SGD iter. 20/49: loss=92.63392537420096, w0=65.39921757403005, w1=9.416292809637218\n",
      "SGD iter. 21/49: loss=0.010968740542483759, w0=65.38440626717178, w1=9.415135087784607\n",
      "SGD iter. 22/49: loss=8.113588887745506, w0=65.78723598027015, w1=9.275562855367863\n",
      "SGD iter. 23/49: loss=126.02123163966816, w0=67.37482050803344, w1=9.434765629669235\n",
      "SGD iter. 24/49: loss=21.615888856451555, w0=68.0323292738526, w1=9.097432346821414\n",
      "SGD iter. 25/49: loss=3.5486259245778062, w0=67.7659225950858, w1=9.804286820674758\n",
      "SGD iter. 26/49: loss=17.63386483146978, w0=67.1720561988068, w1=10.307189487591923\n",
      "SGD iter. 27/49: loss=32.01589219044486, w0=67.97225482652925, w1=10.694959477693038\n",
      "SGD iter. 28/49: loss=1.2231651497926, w0=68.12866231674585, w1=10.609571538834452\n",
      "SGD iter. 29/49: loss=120.66105165384381, w0=69.68211686486654, w1=11.274767676999183\n",
      "SGD iter. 30/49: loss=27.874736971145357, w0=70.42877256826866, w1=11.93705470020899\n",
      "SGD iter. 31/49: loss=0.19995763880795964, w0=70.36553371331254, w1=12.005739006279374\n",
      "SGD iter. 32/49: loss=6.599555832130822, w0=70.72883953028031, w1=11.607809129847567\n",
      "SGD iter. 33/49: loss=29.1565709057359, w0=71.49246995012666, w1=12.049601413647808\n",
      "SGD iter. 34/49: loss=8.602646164016319, w0=71.90726257696606, w1=12.244355158035994\n",
      "SGD iter. 35/49: loss=19.7964537209501, w0=72.53649152927119, w1=13.435252023542558\n",
      "SGD iter. 36/49: loss=4.095014533950204, w0=72.82267379755314, w1=13.515636704793508\n",
      "SGD iter. 37/49: loss=0.0276866736052461, w0=72.84620533962128, w1=13.526475140899787\n",
      "SGD iter. 38/49: loss=0.2618567730063913, w0=72.77383728409863, w1=13.64021528141353\n",
      "SGD iter. 39/49: loss=0.1359319653576562, w0=72.82597785666121, w1=13.538663754457065\n",
      "SGD iter. 40/49: loss=1.4870688791727449, w0=72.6535209705028, w1=13.28784737540494\n",
      "SGD iter. 41/49: loss=68.58745087496847, w0=73.82473786651283, w1=14.128648775303933\n",
      "SGD iter. 42/49: loss=33.26883613350222, w0=73.00903159421254, w1=14.985156566589755\n",
      "SGD iter. 43/49: loss=8.690654639429619, w0=73.42594056843664, w1=14.552249192841174\n",
      "SGD iter. 44/49: loss=51.24138468490717, w0=72.41360283146437, w1=14.352425979559797\n",
      "SGD iter. 45/49: loss=8.508481677525387, w0=72.00108660929789, w1=14.977064025375117\n",
      "SGD iter. 46/49: loss=21.992474851039006, w0=71.33787510681864, w1=14.166981184139642\n",
      "SGD iter. 47/49: loss=13.384244129921322, w0=71.85525783034005, w1=14.06878893828283\n",
      "SGD iter. 48/49: loss=1.1134399217737676, w0=72.00448516843691, w1=14.278799698469529\n",
      "SGD iter. 49/49: loss=31.290937020301005, w0=72.79557223090603, w1=12.957604245410092\n",
      "SGD: execution time=0.043 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e9e16a773b45cab82131e27d7ef3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.8351145358542, w0=51.84746409844846, w1=7.724426406192428\n",
      "GD iter. 1/49: loss=318.28212470159554, w0=67.40170332798299, w1=10.041754328050121\n",
      "GD iter. 2/49: loss=88.6423556165127, w0=72.06797509684336, w1=10.736952704607413\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.945512217574597\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760302, w0=74.01381042445813, w1=11.026850427631794\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.0516072257859, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=65.93086421248087, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249234, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889339, w0=74.06736849193958, w1=11.034829706038408\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=65.93073011140233, w0=74.06776649225755, w1=11.03488900159354\n",
      "GD iter. 12/49: loss=65.93073010339528, w0=74.06779404612573, w1=11.034893106670433\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260976, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260396, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=65.93073010260342, w0=74.06780575927509, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.03489486560434\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873675\n",
      "GD iter. 21/49: loss=65.93073010260339, w0=74.06780585469393, w1=11.034894865954474\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988166\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.034894865988822\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260339, w0=74.06780585492632, w1=11.034894865989093\n",
      "GD iter. 29/49: loss=65.93073010260338, w0=74.06780585492635, w1=11.0348948659891\n",
      "GD iter. 30/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 31/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.005 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db67e81b3e1452d816e7d2ac95836ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute subgradient gradient vector for MAE\n",
    "    # ***************************************************\n",
    "    N = len(y)\n",
    "    error = y - tx @ w\n",
    "    subgrad = -1 / N * tx.T @ np.sign(error)\n",
    "    return subgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute subgradient and loss\n",
    "        # ***************************************************\n",
    "        subgrad = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by subgradient\n",
    "        # ***************************************************\n",
    "        w = w - gamma * subgrad\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=2869.8351145358542, w0=0.7000000000000004, w1=7.625844400394043e-16\n",
      "SubGD iter. 1/499: loss=2818.232650437405, w0=1.4000000000000008, w1=1.5251688800788087e-15\n",
      "SubGD iter. 2/499: loss=2767.120186338957, w0=2.1000000000000014, w1=2.287753320118213e-15\n",
      "SubGD iter. 3/499: loss=2716.497722240506, w0=2.8000000000000016, w1=3.0503377601576174e-15\n",
      "SubGD iter. 4/499: loss=2666.3652581420574, w0=3.5000000000000018, w1=3.812922200197022e-15\n",
      "SubGD iter. 5/499: loss=2616.72279404361, w0=4.200000000000002, w1=4.575506640236426e-15\n",
      "SubGD iter. 6/499: loss=2567.570329945163, w0=4.900000000000002, w1=5.3380910802758305e-15\n",
      "SubGD iter. 7/499: loss=2518.907865846714, w0=5.600000000000002, w1=6.100675520315235e-15\n",
      "SubGD iter. 8/499: loss=2470.735401748265, w0=6.3000000000000025, w1=6.863259960354639e-15\n",
      "SubGD iter. 9/499: loss=2423.052937649816, w0=7.000000000000003, w1=7.625844400394044e-15\n",
      "SubGD iter. 10/499: loss=2375.8604735513672, w0=7.700000000000003, w1=8.388428840433449e-15\n",
      "SubGD iter. 11/499: loss=2329.1580094529195, w0=8.400000000000004, w1=9.151013280472854e-15\n",
      "SubGD iter. 12/499: loss=2282.94554535447, w0=9.100000000000005, w1=9.913597720512259e-15\n",
      "SubGD iter. 13/499: loss=2237.223081256021, w0=9.800000000000006, w1=1.0676182160551664e-14\n",
      "SubGD iter. 14/499: loss=2191.990617157575, w0=10.500000000000007, w1=1.1438766600591069e-14\n",
      "SubGD iter. 15/499: loss=2147.248153059125, w0=11.200000000000008, w1=1.2201351040630474e-14\n",
      "SubGD iter. 16/499: loss=2102.9956889606783, w0=11.90000000000001, w1=1.2963935480669879e-14\n",
      "SubGD iter. 17/499: loss=2059.2332248622292, w0=12.60000000000001, w1=1.3726519920709284e-14\n",
      "SubGD iter. 18/499: loss=2015.9607607637781, w0=13.300000000000011, w1=1.448910436074869e-14\n",
      "SubGD iter. 19/499: loss=1973.1782966653304, w0=14.000000000000012, w1=1.5251688800788094e-14\n",
      "SubGD iter. 20/499: loss=1930.8858325668818, w0=14.700000000000014, w1=1.60142732408275e-14\n",
      "SubGD iter. 21/499: loss=1889.0833684684344, w0=15.400000000000015, w1=1.6776857680866904e-14\n",
      "SubGD iter. 22/499: loss=1847.7709043699842, w0=16.100000000000016, w1=1.753944212090631e-14\n",
      "SubGD iter. 23/499: loss=1806.9484402715373, w0=16.800000000000015, w1=1.8302026560945714e-14\n",
      "SubGD iter. 24/499: loss=1766.615976173087, w0=17.500000000000014, w1=1.906461100098512e-14\n",
      "SubGD iter. 25/499: loss=1726.7735120746406, w0=18.200000000000014, w1=1.9827195441024524e-14\n",
      "SubGD iter. 26/499: loss=1687.4210479761923, w0=18.900000000000013, w1=2.058977988106393e-14\n",
      "SubGD iter. 27/499: loss=1648.5585838777438, w0=19.600000000000012, w1=2.1352364321103335e-14\n",
      "SubGD iter. 28/499: loss=1610.186119779295, w0=20.30000000000001, w1=2.211494876114274e-14\n",
      "SubGD iter. 29/499: loss=1572.3036556808463, w0=21.00000000000001, w1=2.2877533201182145e-14\n",
      "SubGD iter. 30/499: loss=1534.911191582398, w0=21.70000000000001, w1=2.364011764122155e-14\n",
      "SubGD iter. 31/499: loss=1498.00872748395, w0=22.40000000000001, w1=2.4402702081260955e-14\n",
      "SubGD iter. 32/499: loss=1461.5962633855017, w0=23.10000000000001, w1=2.516528652130036e-14\n",
      "SubGD iter. 33/499: loss=1425.6737992870517, w0=23.800000000000008, w1=2.5927870961339765e-14\n",
      "SubGD iter. 34/499: loss=1390.2413351886053, w0=24.500000000000007, w1=2.669045540137917e-14\n",
      "SubGD iter. 35/499: loss=1355.2988710901566, w0=25.200000000000006, w1=2.7453039841418575e-14\n",
      "SubGD iter. 36/499: loss=1320.8464069917068, w0=25.900000000000006, w1=2.821562428145798e-14\n",
      "SubGD iter. 37/499: loss=1286.88394289326, w0=26.600000000000005, w1=2.8978208721497385e-14\n",
      "SubGD iter. 38/499: loss=1253.4114787948113, w0=27.300000000000004, w1=2.9740793161536787e-14\n",
      "SubGD iter. 39/499: loss=1220.429014696362, w0=28.000000000000004, w1=3.050337760157619e-14\n",
      "SubGD iter. 40/499: loss=1187.936550597914, w0=28.700000000000003, w1=3.126596204161559e-14\n",
      "SubGD iter. 41/499: loss=1155.9340864994651, w0=29.400000000000002, w1=3.202854648165499e-14\n",
      "SubGD iter. 42/499: loss=1124.4216224010167, w0=30.1, w1=3.2791130921694394e-14\n",
      "SubGD iter. 43/499: loss=1093.3991583025686, w0=30.8, w1=3.3553715361733796e-14\n",
      "SubGD iter. 44/499: loss=1062.8666942041198, w0=31.5, w1=3.43162998017732e-14\n",
      "SubGD iter. 45/499: loss=1032.8242301056714, w0=32.2, w1=3.50788842418126e-14\n",
      "SubGD iter. 46/499: loss=1003.2717660072228, w0=32.900000000000006, w1=3.5841468681852e-14\n",
      "SubGD iter. 47/499: loss=974.2093019087752, w0=33.60000000000001, w1=3.6604053121891404e-14\n",
      "SubGD iter. 48/499: loss=945.6368378103257, w0=34.30000000000001, w1=3.7366637561930805e-14\n",
      "SubGD iter. 49/499: loss=917.5543737118778, w0=35.000000000000014, w1=3.812922200197021e-14\n",
      "SubGD iter. 50/499: loss=889.9619096134293, w0=35.70000000000002, w1=3.889180644200961e-14\n",
      "SubGD iter. 51/499: loss=862.8594455149799, w0=36.40000000000002, w1=3.965439088204901e-14\n",
      "SubGD iter. 52/499: loss=836.2469814165321, w0=37.10000000000002, w1=4.041697532208841e-14\n",
      "SubGD iter. 53/499: loss=810.1245173180824, w0=37.800000000000026, w1=4.1179559762127815e-14\n",
      "SubGD iter. 54/499: loss=784.492053219635, w0=38.50000000000003, w1=4.1942144202167217e-14\n",
      "SubGD iter. 55/499: loss=759.3495891211861, w0=39.20000000000003, w1=4.270472864220662e-14\n",
      "SubGD iter. 56/499: loss=734.6971250227374, w0=39.900000000000034, w1=4.346731308224602e-14\n",
      "SubGD iter. 57/499: loss=710.5346609242887, w0=40.60000000000004, w1=4.422989752228542e-14\n",
      "SubGD iter. 58/499: loss=686.8621968258401, w0=41.30000000000004, w1=4.4992481962324824e-14\n",
      "SubGD iter. 59/499: loss=663.679732727392, w0=42.00000000000004, w1=4.5755066402364226e-14\n",
      "SubGD iter. 60/499: loss=640.987268628943, w0=42.700000000000045, w1=4.651765084240363e-14\n",
      "SubGD iter. 61/499: loss=618.7848045304947, w0=43.40000000000005, w1=4.728023528244303e-14\n",
      "SubGD iter. 62/499: loss=597.0723404320461, w0=44.10000000000005, w1=4.804281972248243e-14\n",
      "SubGD iter. 63/499: loss=575.8498763335976, w0=44.800000000000054, w1=4.8805404162521834e-14\n",
      "SubGD iter. 64/499: loss=555.1174122351487, w0=45.50000000000006, w1=4.9567988602561235e-14\n",
      "SubGD iter. 65/499: loss=534.8749481367006, w0=46.20000000000006, w1=5.033057304260064e-14\n",
      "SubGD iter. 66/499: loss=515.122484038252, w0=46.90000000000006, w1=5.109315748264004e-14\n",
      "SubGD iter. 67/499: loss=495.86001993980335, w0=47.59306930693076, w1=0.011147845678281268\n",
      "SubGD iter. 68/499: loss=477.1480669293968, w0=48.279207920792146, w1=0.03308574108990965\n",
      "SubGD iter. 69/499: loss=458.9765238171768, w0=48.965346534653534, w1=0.055023636501538034\n",
      "SubGD iter. 70/499: loss=441.27624817364455, w0=49.630693069307, w1=0.10538326388308852\n",
      "SubGD iter. 71/499: loss=424.24408268142946, w0=50.28910891089116, w1=0.16746568532794484\n",
      "SubGD iter. 72/499: loss=407.6944527790811, w0=50.94752475247532, w1=0.22954810677280116\n",
      "SubGD iter. 73/499: loss=391.58218852423465, w0=51.59207920792086, w1=0.31242512932748595\n",
      "SubGD iter. 74/499: loss=375.9955528848726, w0=52.22277227722779, w1=0.4119501328840099\n",
      "SubGD iter. 75/499: loss=360.95695350929515, w0=52.84653465346541, w1=0.5208167847923866\n",
      "SubGD iter. 76/499: loss=346.3748247543324, w0=53.45643564356442, w1=0.6457900912636104\n",
      "SubGD iter. 77/499: loss=332.311770107625, w0=54.059405940594125, w1=0.7796904498577328\n",
      "SubGD iter. 78/499: loss=318.68337247684906, w0=54.655445544554524, w1=0.9197570104995809\n",
      "SubGD iter. 79/499: loss=305.50860343023226, w0=55.244554455445616, w1=1.0670920297850033\n",
      "SubGD iter. 80/499: loss=292.7666734173498, w0=55.81980198019809, w1=1.2261255948210887\n",
      "SubGD iter. 81/499: loss=280.53153011615746, w0=56.36732673267334, w1=1.4107093426222252\n",
      "SubGD iter. 82/499: loss=268.89668417535347, w0=56.900990099009974, w1=1.6058537322202813\n",
      "SubGD iter. 83/499: loss=257.7339200525453, w0=57.4277227722773, w1=1.8087628022939741\n",
      "SubGD iter. 84/499: loss=246.93766902970708, w0=57.9336633663367, w1=2.0285064197514817\n",
      "SubGD iter. 85/499: loss=236.64352344592186, w0=58.4326732673268, w1=2.24943708486729\n",
      "SubGD iter. 86/499: loss=226.7515498304493, w0=58.91089108910898, w1=2.4837982986028466\n",
      "SubGD iter. 87/499: loss=217.35738896411266, w0=59.38217821782185, w1=2.7260245553531632\n",
      "SubGD iter. 88/499: loss=208.28322256993118, w0=59.83960396039611, w1=2.9787423334691487\n",
      "SubGD iter. 89/499: loss=199.60239149197446, w0=60.26237623762383, w1=3.251528669355451\n",
      "SubGD iter. 90/499: loss=191.5160682372001, w0=60.67821782178225, w1=3.5270865794242927\n",
      "SubGD iter. 91/499: loss=183.7548565851672, w0=61.087128712871355, w1=3.8064591839518287\n",
      "SubGD iter. 92/499: loss=176.30486084041306, w0=61.49603960396046, w1=4.085831788479364\n",
      "SubGD iter. 93/499: loss=169.1001222646707, w0=61.891089108910954, w1=4.373839384328622\n",
      "SubGD iter. 94/499: loss=162.25177552382914, w0=62.27920792079214, w1=4.666037469532062\n",
      "SubGD iter. 95/499: loss=155.69742299714315, w0=62.653465346534716, w1=4.959829093241784\n",
      "SubGD iter. 96/499: loss=149.5275267949616, w0=63.020792079207986, w1=5.257057192056655\n",
      "SubGD iter. 97/499: loss=143.64069087621596, w0=63.38118811881195, w1=5.560434316352422\n",
      "SubGD iter. 98/499: loss=138.01748857628525, w0=63.74158415841591, w1=5.86381144064819\n",
      "SubGD iter. 99/499: loss=132.61620926126284, w0=64.08811881188126, w1=6.172402175278565\n",
      "SubGD iter. 100/499: loss=127.54972442477137, w0=64.42772277227729, w1=6.486369310516515\n",
      "SubGD iter. 101/499: loss=122.74087338718536, w0=64.76732673267333, w1=6.800336445754466\n",
      "SubGD iter. 102/499: loss=118.14592856152589, w0=65.10693069306936, w1=7.114303580992416\n",
      "SubGD iter. 103/499: loss=113.76488994779233, w0=65.44653465346539, w1=7.428270716230367\n",
      "SubGD iter. 104/499: loss=109.59775754598506, w0=65.76534653465352, w1=7.747893210218644\n",
      "SubGD iter. 105/499: loss=105.79833542751504, w0=66.07029702970303, w1=8.073669686866923\n",
      "SubGD iter. 106/499: loss=102.29523108809956, w0=66.37524752475254, w1=8.399446163515202\n",
      "SubGD iter. 107/499: loss=98.99125186585245, w0=66.66633663366343, w1=8.732970280417408\n",
      "SubGD iter. 108/499: loss=95.9710318180843, w0=66.95742574257433, w1=9.066494397319614\n",
      "SubGD iter. 109/499: loss=93.1467829761982, w0=67.23465346534661, w1=9.398630319470307\n",
      "SubGD iter. 110/499: loss=90.61539672531033, w0=67.51188118811889, w1=9.730766241621\n",
      "SubGD iter. 111/499: loss=88.27117995547889, w0=67.78910891089117, w1=10.062902163771692\n",
      "SubGD iter. 112/499: loss=86.11413266670375, w0=68.06633663366345, w1=10.36399928997944\n",
      "SubGD iter. 113/499: loss=84.16459694644107, w0=68.32970297029712, w1=10.66046690927363\n",
      "SubGD iter. 114/499: loss=82.46374060728368, w0=68.59306930693079, w1=10.943174379960832\n",
      "SubGD iter. 115/499: loss=80.92130656136128, w0=68.85643564356445, w1=11.225881850648033\n",
      "SubGD iter. 116/499: loss=79.52815785669307, w0=69.11287128712881, w1=11.504395843582225\n",
      "SubGD iter. 117/499: loss=78.31663397216138, w0=69.35544554455456, w1=11.78820189306777\n",
      "SubGD iter. 118/499: loss=77.31763568851017, w0=69.58415841584169, w1=12.06091146519099\n",
      "SubGD iter. 119/499: loss=76.5086323125276, w0=69.8059405940595, w1=12.324245668386068\n",
      "SubGD iter. 120/499: loss=75.84369059931609, w0=70.02772277227733, w1=12.587579871581145\n",
      "SubGD iter. 121/499: loss=75.29728112325199, w0=70.25643564356446, w1=12.824765405096503\n",
      "SubGD iter. 122/499: loss=74.79581982001415, w0=70.47821782178228, w1=13.065616959310168\n",
      "SubGD iter. 123/499: loss=74.43521733660013, w0=70.6930693069308, w1=13.302953389983932\n",
      "SubGD iter. 124/499: loss=74.1971982209247, w0=70.8940594059407, w1=13.525403099312937\n",
      "SubGD iter. 125/499: loss=74.06837899395485, w0=71.08811881188129, w1=13.742945617944232\n",
      "SubGD iter. 126/499: loss=74.03676697743111, w0=71.27524752475257, w1=13.953548196006865\n",
      "SubGD iter. 127/499: loss=74.08918974672676, w0=71.46237623762386, w1=14.1641507740695\n",
      "SubGD iter. 128/499: loss=74.22098311708994, w0=71.62178217821791, w1=14.349779559473198\n",
      "SubGD iter. 129/499: loss=74.41647628166011, w0=71.75346534653474, w1=14.516890107612335\n",
      "SubGD iter. 130/499: loss=74.670961528338, w0=71.87128712871295, w1=14.67079118532421\n",
      "SubGD iter. 131/499: loss=74.95294838238377, w0=71.95445544554464, w1=14.780276456654546\n",
      "SubGD iter. 132/499: loss=75.17779670886813, w0=72.03762376237633, w1=14.889761727984881\n",
      "SubGD iter. 133/499: loss=75.42154902891541, w0=72.1069306930694, w1=14.985916181776751\n",
      "SubGD iter. 134/499: loss=75.65853052170132, w0=72.17623762376247, w1=15.082070635568622\n",
      "SubGD iter. 135/499: loss=75.90956114411341, w0=72.24554455445555, w1=15.178225089360492\n",
      "SubGD iter. 136/499: loss=76.17464089615157, w0=72.30099009901001, w1=15.259723489715935\n",
      "SubGD iter. 137/499: loss=76.41613751021131, w0=72.34950495049516, w1=15.335091856448162\n",
      "SubGD iter. 138/499: loss=76.6528561800645, w0=72.39801980198031, w1=15.41046022318039\n",
      "SubGD iter. 139/499: loss=76.89760893143622, w0=72.43267326732685, w1=15.46996178675575\n",
      "SubGD iter. 140/499: loss=77.1024686879576, w0=72.46039603960408, w1=15.518645285832834\n",
      "SubGD iter. 141/499: loss=77.274622173525, w0=72.48811881188131, w1=15.561592159086512\n",
      "SubGD iter. 142/499: loss=77.4239298712533, w0=72.50198019801992, w1=15.59782833203255\n",
      "SubGD iter. 143/499: loss=77.56681600428627, w0=72.52277227722784, w1=15.624722856626738\n",
      "SubGD iter. 144/499: loss=77.65755497253167, w0=72.55049504950507, w1=15.642690329098025\n",
      "SubGD iter. 145/499: loss=77.69773565765107, w0=72.56435643564369, w1=15.664356578291116\n",
      "SubGD iter. 146/499: loss=77.77686805360923, w0=72.58514851485161, w1=15.677095775361309\n",
      "SubGD iter. 147/499: loss=77.80488113813023, w0=72.60594059405953, w1=15.689834972431502\n",
      "SubGD iter. 148/499: loss=77.83348882035098, w0=72.62673267326745, w1=15.702574169501695\n",
      "SubGD iter. 149/499: loss=77.86269110027155, w0=72.64059405940607, w1=15.724240418694786\n",
      "SubGD iter. 150/499: loss=77.94417771357979, w0=72.66138613861399, w1=15.736979615764978\n",
      "SubGD iter. 151/499: loss=77.97453880885689, w0=72.6683168316833, w1=15.748110294231305\n",
      "SubGD iter. 152/499: loss=78.01721470220245, w0=72.6752475247526, w1=15.759240972697631\n",
      "SubGD iter. 153/499: loss=78.06006252205755, w0=72.68217821782191, w1=15.770371651163957\n",
      "SubGD iter. 154/499: loss=78.10308226842221, w0=72.68217821782191, w1=15.774323911906711\n",
      "SubGD iter. 155/499: loss=78.12180591760094, w0=72.68217821782191, w1=15.778276172649464\n",
      "SubGD iter. 156/499: loss=78.1405451871447, w0=72.68217821782191, w1=15.782228433392218\n",
      "SubGD iter. 157/499: loss=78.1593000770534, w0=72.68217821782191, w1=15.786180694134972\n",
      "SubGD iter. 158/499: loss=78.1780705873271, w0=72.68217821782191, w1=15.790132954877725\n",
      "SubGD iter. 159/499: loss=78.19685671796577, w0=72.68217821782191, w1=15.794085215620479\n",
      "SubGD iter. 160/499: loss=78.21565846896942, w0=72.68217821782191, w1=15.798037476363232\n",
      "SubGD iter. 161/499: loss=78.23447584033804, w0=72.68217821782191, w1=15.801989737105986\n",
      "SubGD iter. 162/499: loss=78.25330883207167, w0=72.68217821782191, w1=15.80594199784874\n",
      "SubGD iter. 163/499: loss=78.27215744417025, w0=72.68217821782191, w1=15.809894258591493\n",
      "SubGD iter. 164/499: loss=78.29102167663382, w0=72.68217821782191, w1=15.813846519334247\n",
      "SubGD iter. 165/499: loss=78.30990152946235, w0=72.68217821782191, w1=15.817798780077\n",
      "SubGD iter. 166/499: loss=78.32879700265586, w0=72.68217821782191, w1=15.821751040819754\n",
      "SubGD iter. 167/499: loss=78.34770809621438, w0=72.68217821782191, w1=15.825703301562507\n",
      "SubGD iter. 168/499: loss=78.36663481013785, w0=72.68217821782191, w1=15.82965556230526\n",
      "SubGD iter. 169/499: loss=78.38557714442632, w0=72.68217821782191, w1=15.833607823048014\n",
      "SubGD iter. 170/499: loss=78.4045350990798, w0=72.68217821782191, w1=15.837560083790768\n",
      "SubGD iter. 171/499: loss=78.42350867409819, w0=72.68217821782191, w1=15.841512344533522\n",
      "SubGD iter. 172/499: loss=78.44249786948157, w0=72.68217821782191, w1=15.845464605276275\n",
      "SubGD iter. 173/499: loss=78.46150268522993, w0=72.68217821782191, w1=15.849416866019029\n",
      "SubGD iter. 174/499: loss=78.48052312134328, w0=72.68217821782191, w1=15.853369126761782\n",
      "SubGD iter. 175/499: loss=78.49955917782161, w0=72.68217821782191, w1=15.857321387504536\n",
      "SubGD iter. 176/499: loss=78.51861085466493, w0=72.68217821782191, w1=15.86127364824729\n",
      "SubGD iter. 177/499: loss=78.53767815187322, w0=72.68217821782191, w1=15.865225908990043\n",
      "SubGD iter. 178/499: loss=78.5567610694465, w0=72.68217821782191, w1=15.869178169732796\n",
      "SubGD iter. 179/499: loss=78.57585960738474, w0=72.68217821782191, w1=15.87313043047555\n",
      "SubGD iter. 180/499: loss=78.59497376568797, w0=72.68217821782191, w1=15.877082691218304\n",
      "SubGD iter. 181/499: loss=78.61410354435615, w0=72.68217821782191, w1=15.881034951961057\n",
      "SubGD iter. 182/499: loss=78.63324894338935, w0=72.68217821782191, w1=15.88498721270381\n",
      "SubGD iter. 183/499: loss=78.6524099627875, w0=72.68217821782191, w1=15.888939473446564\n",
      "SubGD iter. 184/499: loss=78.67158660255065, w0=72.68217821782191, w1=15.892891734189318\n",
      "SubGD iter. 185/499: loss=78.69077886267875, w0=72.68217821782191, w1=15.896843994932071\n",
      "SubGD iter. 186/499: loss=78.70998674317185, w0=72.68217821782191, w1=15.900796255674825\n",
      "SubGD iter. 187/499: loss=78.72921024402993, w0=72.68217821782191, w1=15.904748516417579\n",
      "SubGD iter. 188/499: loss=78.748449365253, w0=72.68217821782191, w1=15.908700777160332\n",
      "SubGD iter. 189/499: loss=78.76770410684102, w0=72.68217821782191, w1=15.912653037903086\n",
      "SubGD iter. 190/499: loss=78.78697446879403, w0=72.6752475247526, w1=15.910526938117348\n",
      "SubGD iter. 191/499: loss=78.78623350545433, w0=72.6752475247526, w1=15.914479198860102\n",
      "SubGD iter. 192/499: loss=78.80551108487161, w0=72.6752475247526, w1=15.918431459602855\n",
      "SubGD iter. 193/499: loss=78.82480428465385, w0=72.6683168316833, w1=15.916305359817118\n",
      "SubGD iter. 194/499: loss=78.82409907031943, w0=72.6683168316833, w1=15.920257620559871\n",
      "SubGD iter. 195/499: loss=78.84339948756596, w0=72.6683168316833, w1=15.924209881302625\n",
      "SubGD iter. 196/499: loss=78.86271552517744, w0=72.6683168316833, w1=15.928162142045379\n",
      "SubGD iter. 197/499: loss=78.88204718315392, w0=72.66138613861399, w1=15.926036042259641\n",
      "SubGD iter. 198/499: loss=78.88136931492404, w0=72.66138613861399, w1=15.929988303002395\n",
      "SubGD iter. 199/499: loss=78.90070819036477, w0=72.66138613861399, w1=15.933940563745148\n",
      "SubGD iter. 200/499: loss=78.92006268617048, w0=72.65445544554468, w1=15.93181446395941\n",
      "SubGD iter. 201/499: loss=78.9194205669459, w0=72.65445544554468, w1=15.935766724702164\n",
      "SubGD iter. 202/499: loss=78.93878228021588, w0=72.65445544554468, w1=15.939718985444918\n",
      "SubGD iter. 203/499: loss=78.95815961385082, w0=72.65445544554468, w1=15.943671246187671\n",
      "SubGD iter. 204/499: loss=78.97755256785074, w0=72.64752475247538, w1=15.941545146401934\n",
      "SubGD iter. 205/499: loss=78.97693779473073, w0=72.64752475247538, w1=15.945497407144687\n",
      "SubGD iter. 206/499: loss=78.9963379661949, w0=72.64752475247538, w1=15.949449667887441\n",
      "SubGD iter. 207/499: loss=79.01575375802408, w0=72.64059405940607, w1=15.947323568101703\n",
      "SubGD iter. 208/499: loss=79.01517473390936, w0=72.64059405940607, w1=15.951275828844457\n",
      "SubGD iter. 209/499: loss=79.03459774320278, w0=72.64059405940607, w1=15.95522808958721\n",
      "SubGD iter. 210/499: loss=79.05403637286119, w0=72.64059405940607, w1=15.959180350329964\n",
      "SubGD iter. 211/499: loss=79.07349062288456, w0=72.63366336633676, w1=15.957054250544227\n",
      "SubGD iter. 212/499: loss=79.0729389448744, w0=72.63366336633676, w1=15.96100651128698\n",
      "SubGD iter. 213/499: loss=79.09240041236205, w0=72.63366336633676, w1=15.964958772029734\n",
      "SubGD iter. 214/499: loss=79.11187750021469, w0=72.62673267326745, w1=15.962832672243996\n",
      "SubGD iter. 215/499: loss=79.1113615712098, w0=72.63366336633676, w1=15.9673013720514\n",
      "SubGD iter. 216/499: loss=79.12342941191521, w0=72.62673267326745, w1=15.965175272265663\n",
      "SubGD iter. 217/499: loss=79.12290850230893, w0=72.63366336633676, w1=15.969643972073067\n",
      "SubGD iter. 218/499: loss=79.1349868113906, w0=72.62673267326745, w1=15.96751787228733\n",
      "SubGD iter. 219/499: loss=79.13446092118292, w0=72.63366336633676, w1=15.971986572094734\n",
      "SubGD iter. 220/499: loss=79.14654969864088, w0=72.62673267326745, w1=15.969860472308996\n",
      "SubGD iter. 221/499: loss=79.14601882783178, w0=72.63366336633676, w1=15.9743291721164\n",
      "SubGD iter. 222/499: loss=79.158118073666, w0=72.62673267326745, w1=15.972203072330663\n",
      "SubGD iter. 223/499: loss=79.15758222225551, w0=72.62673267326745, w1=15.970593411609576\n",
      "SubGD iter. 224/499: loss=79.14963612667167, w0=72.63366336633676, w1=15.97506211141698\n",
      "SubGD iter. 225/499: loss=79.16173864779161, w0=72.62673267326745, w1=15.972936011631242\n",
      "SubGD iter. 226/499: loss=79.16120123807903, w0=72.62673267326745, w1=15.971326350910156\n",
      "SubGD iter. 227/499: loss=79.15325396271157, w0=72.63366336633676, w1=15.97579505071756\n",
      "SubGD iter. 228/499: loss=79.16535975911721, w0=72.62673267326745, w1=15.973668950931822\n",
      "SubGD iter. 229/499: loss=79.16482079110254, w0=72.62673267326745, w1=15.972059290210735\n",
      "SubGD iter. 230/499: loss=79.15687233595149, w0=72.62673267326745, w1=15.970449629489648\n",
      "SubGD iter. 231/499: loss=79.14892647180811, w0=72.63366336633676, w1=15.974918329297052\n",
      "SubGD iter. 232/499: loss=79.1610283504089, w0=72.62673267326745, w1=15.972792229511315\n",
      "SubGD iter. 233/499: loss=79.16049124639146, w0=72.62673267326745, w1=15.971182568790228\n",
      "SubGD iter. 234/499: loss=79.15254420246444, w0=72.63366336633676, w1=15.975651268597632\n",
      "SubGD iter. 235/499: loss=79.16464935635094, w0=72.62673267326745, w1=15.973525168811895\n",
      "SubGD iter. 236/499: loss=79.16411069403141, w0=72.62673267326745, w1=15.971915508090808\n",
      "SubGD iter. 237/499: loss=79.15616247032082, w0=72.63366336633676, w1=15.976384207898212\n",
      "SubGD iter. 238/499: loss=79.16827089949302, w0=72.62673267326745, w1=15.974258108112474\n",
      "SubGD iter. 239/499: loss=79.16773067887141, w0=72.62673267326745, w1=15.972648447391387\n",
      "SubGD iter. 240/499: loss=79.15978127537718, w0=72.62673267326745, w1=15.9710387866703\n",
      "SubGD iter. 241/499: loss=79.15183446289063, w0=72.63366336633676, w1=15.975507486477705\n",
      "SubGD iter. 242/499: loss=79.163938974258, w0=72.62673267326745, w1=15.973381386691967\n",
      "SubGD iter. 243/499: loss=79.16340061763357, w0=72.62673267326745, w1=15.97177172597088\n",
      "SubGD iter. 244/499: loss=79.15545262536341, w0=72.63366336633676, w1=15.976240425778284\n",
      "SubGD iter. 245/499: loss=79.1675604120165, w0=72.62673267326745, w1=15.974114325992547\n",
      "SubGD iter. 246/499: loss=79.16702049709, w0=72.62673267326745, w1=15.97250466527146\n",
      "SubGD iter. 247/499: loss=79.15907132503624, w0=72.62673267326745, w1=15.970895004550373\n",
      "SubGD iter. 248/499: loss=79.1511247439901, w0=72.63366336633676, w1=15.975363704357777\n",
      "SubGD iter. 249/499: loss=79.16322861283832, w0=72.62673267326745, w1=15.97323760457204\n",
      "SubGD iter. 250/499: loss=79.16269056190906, w0=72.62673267326745, w1=15.971627943850953\n",
      "SubGD iter. 251/499: loss=79.15474280107931, w0=72.63366336633676, w1=15.976096643658357\n",
      "SubGD iter. 252/499: loss=79.16684994521326, w0=72.62673267326745, w1=15.97397054387262\n",
      "SubGD iter. 253/499: loss=79.16631033598189, w0=72.62673267326745, w1=15.972360883151532\n",
      "SubGD iter. 254/499: loss=79.15836139536856, w0=72.62673267326745, w1=15.970751222430446\n",
      "SubGD iter. 255/499: loss=79.15041504576286, w0=72.63366336633676, w1=15.97521992223785\n",
      "SubGD iter. 256/499: loss=79.16251827209196, w0=72.62673267326745, w1=15.973093822452112\n",
      "SubGD iter. 257/499: loss=79.16198052685783, w0=72.62673267326745, w1=15.971484161731025\n",
      "SubGD iter. 258/499: loss=79.15403299746852, w0=72.63366336633676, w1=15.97595286153843\n",
      "SubGD iter. 259/499: loss=79.16613949908331, w0=72.62673267326745, w1=15.973826761752692\n",
      "SubGD iter. 260/499: loss=79.1656001955471, w0=72.62673267326745, w1=15.972217101031605\n",
      "SubGD iter. 261/499: loss=79.15765148637419, w0=72.62673267326745, w1=15.970607440310518\n",
      "SubGD iter. 262/499: loss=79.14970536820891, w0=72.63366336633676, w1=15.975076140117922\n",
      "SubGD iter. 263/499: loss=79.16180795201889, w0=72.62673267326745, w1=15.972950040332185\n",
      "SubGD iter. 264/499: loss=79.16127051247989, w0=72.62673267326745, w1=15.971340379611098\n",
      "SubGD iter. 265/499: loss=79.153323214531, w0=72.63366336633676, w1=15.975809079418502\n",
      "SubGD iter. 266/499: loss=79.16542907362668, w0=72.62673267326745, w1=15.973682979632764\n",
      "SubGD iter. 267/499: loss=79.1648900757856, w0=72.62673267326745, w1=15.972073318911677\n",
      "SubGD iter. 268/499: loss=79.15694159805312, w0=72.62673267326745, w1=15.97046365819059\n",
      "SubGD iter. 269/499: loss=79.14899571132827, w0=72.63366336633676, w1=15.974932357997995\n",
      "SubGD iter. 270/499: loss=79.16109765261912, w0=72.62673267326745, w1=15.972806258212257\n",
      "SubGD iter. 271/499: loss=79.16056051877524, w0=72.62673267326745, w1=15.97119659749117\n",
      "SubGD iter. 272/499: loss=79.1526134522668, w0=72.63366336633676, w1=15.975665297298574\n",
      "SubGD iter. 273/499: loss=79.16471866884335, w0=72.62673267326745, w1=15.973539197512837\n",
      "SubGD iter. 274/499: loss=79.16417997669738, w0=72.62673267326745, w1=15.97192953679175\n",
      "SubGD iter. 275/499: loss=79.15623173040535, w0=72.63366336633676, w1=15.976398236599154\n",
      "SubGD iter. 276/499: loss=79.16834022226762, w0=72.62673267326745, w1=15.974272136813417\n",
      "SubGD iter. 277/499: loss=79.16779997181956, w0=72.62673267326745, w1=15.97266247609233\n",
      "SubGD iter. 278/499: loss=79.15985054574391, w0=72.62673267326745, w1=15.971052815371243\n",
      "SubGD iter. 279/499: loss=79.15190371067588, w0=72.63366336633676, w1=15.975521515178647\n",
      "SubGD iter. 280/499: loss=79.16400828473331, w0=72.62673267326745, w1=15.97339541539291\n",
      "SubGD iter. 281/499: loss=79.1634698982825, w0=72.62673267326745, w1=15.971785754671822\n",
      "SubGD iter. 282/499: loss=79.15552188343088, w0=72.63366336633676, w1=15.976254454479227\n",
      "SubGD iter. 283/499: loss=79.16762973277402, w0=72.62673267326745, w1=15.97412835469349\n",
      "SubGD iter. 284/499: loss=79.1670897880211, w0=72.62673267326745, w1=15.972518693972402\n",
      "SubGD iter. 285/499: loss=79.15914059338587, w0=72.62673267326745, w1=15.970909033251315\n",
      "SubGD iter. 286/499: loss=79.15119398975828, w0=72.63366336633676, w1=15.97537773305872\n",
      "SubGD iter. 287/499: loss=79.16329792129659, w0=72.62673267326745, w1=15.973251633272982\n",
      "SubGD iter. 288/499: loss=79.1627598405409, w0=72.62673267326745, w1=15.971641972551895\n",
      "SubGD iter. 289/499: loss=79.1548120571297, w0=72.63366336633676, w1=15.9761106723593\n",
      "SubGD iter. 290/499: loss=79.1669192639537, w0=72.62673267326745, w1=15.973984572573562\n",
      "SubGD iter. 291/499: loss=79.16637962489592, w0=72.62673267326745, w1=15.972374911852475\n",
      "SubGD iter. 292/499: loss=79.15843066170113, w0=72.62673267326745, w1=15.970765251131388\n",
      "SubGD iter. 293/499: loss=79.15048428951397, w0=72.63366336633676, w1=15.975233950938792\n",
      "SubGD iter. 294/499: loss=79.16258757853313, w0=72.62673267326745, w1=15.973107851153054\n",
      "SubGD iter. 295/499: loss=79.16204980347257, w0=72.62673267326745, w1=15.971498190431968\n",
      "SubGD iter. 296/499: loss=79.15410225150183, w0=72.63366336633676, w1=15.975966890239372\n",
      "SubGD iter. 297/499: loss=79.1662088158067, w0=72.62673267326745, w1=15.973840790453634\n",
      "SubGD iter. 298/499: loss=79.16566948244406, w0=72.62673267326745, w1=15.972231129732547\n",
      "SubGD iter. 299/499: loss=79.15772075068968, w0=72.62673267326745, w1=15.97062146901146\n",
      "SubGD iter. 300/499: loss=79.14977460994294, w0=72.63366336633676, w1=15.975090168818864\n",
      "SubGD iter. 301/499: loss=79.16187725644299, w0=72.62673267326745, w1=15.972964069033127\n",
      "SubGD iter. 302/499: loss=79.16133978707757, w0=72.62673267326745, w1=15.97135440831204\n",
      "SubGD iter. 303/499: loss=79.15339246654723, w0=72.63366336633676, w1=15.975823108119444\n",
      "SubGD iter. 304/499: loss=79.16549838833299, w0=72.62673267326745, w1=15.973697008333707\n",
      "SubGD iter. 305/499: loss=79.16495936066546, w0=72.62673267326745, w1=15.97208734761262\n",
      "SubGD iter. 306/499: loss=79.15701086035155, w0=72.62673267326745, w1=15.970477686891533\n",
      "SubGD iter. 307/499: loss=79.14906495104526, w0=72.63366336633676, w1=15.974946386698937\n",
      "SubGD iter. 308/499: loss=79.16116695502615, w0=72.62673267326745, w1=15.9728202869132\n",
      "SubGD iter. 309/499: loss=79.16062979135584, w0=72.62673267326745, w1=15.971210626192113\n",
      "SubGD iter. 310/499: loss=79.15268270226595, w0=72.63366336633676, w1=15.975679325999517\n",
      "SubGD iter. 311/499: loss=79.16478798153257, w0=72.62673267326745, w1=15.97355322621378\n",
      "SubGD iter. 312/499: loss=79.16424925956022, w0=72.62673267326745, w1=15.971943565492692\n",
      "SubGD iter. 313/499: loss=79.15630099068669, w0=72.63366336633676, w1=15.976412265300096\n",
      "SubGD iter. 314/499: loss=79.16840954523902, w0=72.62673267326745, w1=15.974286165514359\n",
      "SubGD iter. 315/499: loss=79.16786926496454, w0=72.62673267326745, w1=15.972676504793272\n",
      "SubGD iter. 316/499: loss=79.15991981630745, w0=72.62673267326745, w1=15.971066844072185\n",
      "SubGD iter. 317/499: loss=79.15197295865798, w0=72.63366336633676, w1=15.97553554387959\n",
      "SubGD iter. 318/499: loss=79.16407759540546, w0=72.62673267326745, w1=15.973409444093852\n",
      "SubGD iter. 319/499: loss=79.16353917912822, w0=72.62673267326745, w1=15.971799783372765\n",
      "SubGD iter. 320/499: loss=79.15559114169514, w0=72.63366336633676, w1=15.976268483180169\n",
      "SubGD iter. 321/499: loss=79.16769905372831, w0=72.62673267326745, w1=15.974142383394431\n",
      "SubGD iter. 322/499: loss=79.167159079149, w0=72.62673267326745, w1=15.972532722673344\n",
      "SubGD iter. 323/499: loss=79.15920986193231, w0=72.62673267326745, w1=15.970923061952258\n",
      "SubGD iter. 324/499: loss=79.15126323572328, w0=72.63366336633676, w1=15.975391761759662\n",
      "SubGD iter. 325/499: loss=79.16336722995163, w0=72.62673267326745, w1=15.973265661973924\n",
      "SubGD iter. 326/499: loss=79.16282911936953, w0=72.62673267326745, w1=15.971656001252837\n",
      "SubGD iter. 327/499: loss=79.15488131337689, w0=72.63366336633676, w1=15.976124701060241\n",
      "SubGD iter. 328/499: loss=79.16698858289094, w0=72.62673267326745, w1=15.973998601274504\n",
      "SubGD iter. 329/499: loss=79.16644891400675, w0=72.62673267326745, w1=15.972388940553417\n",
      "SubGD iter. 330/499: loss=79.1584999282305, w0=72.62673267326745, w1=15.97077927983233\n",
      "SubGD iter. 331/499: loss=79.1505535334619, w0=72.63366336633676, w1=15.975247979639734\n",
      "SubGD iter. 332/499: loss=79.1626568851711, w0=72.62673267326745, w1=15.973121879853997\n",
      "SubGD iter. 333/499: loss=79.16211908028414, w0=72.62673267326745, w1=15.97151221913291\n",
      "SubGD iter. 334/499: loss=79.15417150573192, w0=72.63366336633676, w1=15.975980918940314\n",
      "SubGD iter. 335/499: loss=79.16627813272686, w0=72.62673267326745, w1=15.973854819154576\n",
      "SubGD iter. 336/499: loss=79.1657387695378, w0=72.62673267326745, w1=15.97224515843349\n",
      "SubGD iter. 337/499: loss=79.15779001520198, w0=72.62673267326745, w1=15.970635497712403\n",
      "SubGD iter. 338/499: loss=79.14984385187381, w0=72.63366336633676, w1=15.975104197519807\n",
      "SubGD iter. 339/499: loss=79.16194656106389, w0=72.62673267326745, w1=15.97297809773407\n",
      "SubGD iter. 340/499: loss=79.16140906187205, w0=72.62673267326745, w1=15.971368437012982\n",
      "SubGD iter. 341/499: loss=79.15346171876027, w0=72.63366336633676, w1=15.975837136820386\n",
      "SubGD iter. 342/499: loss=79.16556770323606, w0=72.62673267326745, w1=15.973711037034649\n",
      "SubGD iter. 343/499: loss=79.16502864574214, w0=72.62673267326745, w1=15.972101376313562\n",
      "SubGD iter. 344/499: loss=79.15708012284676, w0=72.62673267326745, w1=15.970491715592475\n",
      "SubGD iter. 345/499: loss=79.14913419095903, w0=72.63366336633676, w1=15.97496041539988\n",
      "SubGD iter. 346/499: loss=79.16123625762994, w0=72.62673267326745, w1=15.972834315614142\n",
      "SubGD iter. 347/499: loss=79.16069906413325, w0=72.62673267326745, w1=15.971224654893055\n",
      "SubGD iter. 348/499: loss=79.15275195246193, w0=72.63366336633676, w1=15.975693354700459\n",
      "SubGD iter. 349/499: loss=79.16485729441857, w0=72.62673267326745, w1=15.973567254914721\n",
      "SubGD iter. 350/499: loss=79.16431854261977, w0=72.62673267326745, w1=15.971957594193634\n",
      "SubGD iter. 351/499: loss=79.15637025116483, w0=72.63366336633676, w1=15.976426294001039\n",
      "SubGD iter. 352/499: loss=79.1684788684072, w0=72.62673267326745, w1=15.974300194215301\n",
      "SubGD iter. 353/499: loss=79.16793855830633, w0=72.62673267326745, w1=15.972690533494214\n",
      "SubGD iter. 354/499: loss=79.15998908706776, w0=72.62673267326745, w1=15.971080872773127\n",
      "SubGD iter. 355/499: loss=79.15204220683685, w0=72.63366336633676, w1=15.975549572580531\n",
      "SubGD iter. 356/499: loss=79.16414690627438, w0=72.62673267326745, w1=15.973423472794794\n",
      "SubGD iter. 357/499: loss=79.16360846017072, w0=72.62673267326745, w1=15.971813812073707\n",
      "SubGD iter. 358/499: loss=79.15566040015621, w0=72.63366336633676, w1=15.976282511881111\n",
      "SubGD iter. 359/499: loss=79.16776837487944, w0=72.62673267326745, w1=15.974156412095374\n",
      "SubGD iter. 360/499: loss=79.16722837047371, w0=72.62673267326745, w1=15.972546751374287\n",
      "SubGD iter. 361/499: loss=79.15927913067557, w0=72.62673267326745, w1=15.9709370906532\n",
      "SubGD iter. 362/499: loss=79.15133248188509, w0=72.63366336633676, w1=15.975405790460604\n",
      "SubGD iter. 363/499: loss=79.16343653880348, w0=72.62673267326745, w1=15.973279690674866\n",
      "SubGD iter. 364/499: loss=79.16289839839496, w0=72.62673267326745, w1=15.97167002995378\n",
      "SubGD iter. 365/499: loss=79.15495056982087, w0=72.63366336633676, w1=15.976138729761184\n",
      "SubGD iter. 366/499: loss=79.167057902025, w0=72.62673267326745, w1=15.974012629975446\n",
      "SubGD iter. 367/499: loss=79.16651820331438, w0=72.62673267326745, w1=15.97240296925436\n",
      "SubGD iter. 368/499: loss=79.15856919495668, w0=72.62673267326745, w1=15.970793308533272\n",
      "SubGD iter. 369/499: loss=79.15062277760663, w0=72.63366336633676, w1=15.975262008340676\n",
      "SubGD iter. 370/499: loss=79.16272619200589, w0=72.62673267326745, w1=15.973135908554939\n",
      "SubGD iter. 371/499: loss=79.1621883572925, w0=72.62673267326745, w1=15.971526247833852\n",
      "SubGD iter. 372/499: loss=79.15424076015886, w0=72.63366336633676, w1=15.975994947641256\n",
      "SubGD iter. 373/499: loss=79.16634744984383, w0=72.62673267326745, w1=15.973868847855519\n",
      "SubGD iter. 374/499: loss=79.16580805682834, w0=72.62673267326745, w1=15.972259187134432\n",
      "SubGD iter. 375/499: loss=79.15785927991108, w0=72.62673267326745, w1=15.970649526413345\n",
      "SubGD iter. 376/499: loss=79.14991309400145, w0=72.63366336633676, w1=15.975118226220749\n",
      "SubGD iter. 377/499: loss=79.16201586588157, w0=72.62673267326745, w1=15.972992126435011\n",
      "SubGD iter. 378/499: loss=79.16147833686334, w0=72.62673267326745, w1=15.971382465713925\n",
      "SubGD iter. 379/499: loss=79.1535309711701, w0=72.63366336633676, w1=15.975851165521329\n",
      "SubGD iter. 380/499: loss=79.16563701833594, w0=72.62673267326745, w1=15.973725065735591\n",
      "SubGD iter. 381/499: loss=79.16509793101561, w0=72.62673267326745, w1=15.972115405014504\n",
      "SubGD iter. 382/499: loss=79.15714938553877, w0=72.62673267326745, w1=15.970505744293417\n",
      "SubGD iter. 383/499: loss=79.1492034310696, w0=72.63366336633676, w1=15.974974444100821\n",
      "SubGD iter. 384/499: loss=79.1613055604306, w0=72.62673267326745, w1=15.972848344315084\n",
      "SubGD iter. 385/499: loss=79.16076833710747, w0=72.62673267326745, w1=15.971238683593997\n",
      "SubGD iter. 386/499: loss=79.15282120285467, w0=72.63366336633676, w1=15.975707383401401\n",
      "SubGD iter. 387/499: loss=79.16492660750139, w0=72.62673267326745, w1=15.973581283615664\n",
      "SubGD iter. 388/499: loss=79.16438782587618, w0=72.62673267326745, w1=15.971971622894577\n",
      "SubGD iter. 389/499: loss=79.15643951183976, w0=72.63366336633676, w1=15.976440322701981\n",
      "SubGD iter. 390/499: loss=79.16854819177222, w0=72.62673267326745, w1=15.974314222916243\n",
      "SubGD iter. 391/499: loss=79.16800785184492, w0=72.62673267326745, w1=15.972704562195156\n",
      "SubGD iter. 392/499: loss=79.1600583580249, w0=72.62673267326745, w1=15.97109490147407\n",
      "SubGD iter. 393/499: loss=79.15211145521255, w0=72.63366336633676, w1=15.975563601281474\n",
      "SubGD iter. 394/499: loss=79.16421621734013, w0=72.62673267326745, w1=15.973437501495736\n",
      "SubGD iter. 395/499: loss=79.16367774141004, w0=72.62673267326745, w1=15.97182784077465\n",
      "SubGD iter. 396/499: loss=79.15572965881408, w0=72.63366336633676, w1=15.976296540582053\n",
      "SubGD iter. 397/499: loss=79.1678376962274, w0=72.62673267326745, w1=15.974170440796316\n",
      "SubGD iter. 398/499: loss=79.16729766199522, w0=72.62673267326745, w1=15.972560780075229\n",
      "SubGD iter. 399/499: loss=79.15934839961564, w0=72.62673267326745, w1=15.970951119354142\n",
      "SubGD iter. 400/499: loss=79.1514017282437, w0=72.63366336633676, w1=15.975419819161546\n",
      "SubGD iter. 401/499: loss=79.16350584785216, w0=72.62673267326745, w1=15.973293719375809\n",
      "SubGD iter. 402/499: loss=79.1629676776172, w0=72.62673267326745, w1=15.971684058654722\n",
      "SubGD iter. 403/499: loss=79.15501982646167, w0=72.63366336633676, w1=15.976152758462126\n",
      "SubGD iter. 404/499: loss=79.16712722135586, w0=72.62673267326745, w1=15.974026658676388\n",
      "SubGD iter. 405/499: loss=79.16658749281882, w0=72.62673267326745, w1=15.972416997955301\n",
      "SubGD iter. 406/499: loss=79.15863846187966, w0=72.62673267326745, w1=15.970807337234215\n",
      "SubGD iter. 407/499: loss=79.15069202194816, w0=72.63366336633676, w1=15.975276037041619\n",
      "SubGD iter. 408/499: loss=79.16279549903749, w0=72.62673267326745, w1=15.973149937255881\n",
      "SubGD iter. 409/499: loss=79.16225763449769, w0=72.62673267326745, w1=15.971540276534794\n",
      "SubGD iter. 410/499: loss=79.15431001478257, w0=72.63366336633676, w1=15.976008976342198\n",
      "SubGD iter. 411/499: loss=79.1664167671576, w0=72.62673267326745, w1=15.97388287655646\n",
      "SubGD iter. 412/499: loss=79.1658773443157, w0=72.62673267326745, w1=15.972273215835374\n",
      "SubGD iter. 413/499: loss=79.15792854481698, w0=72.62673267326745, w1=15.970663555114287\n",
      "SubGD iter. 414/499: loss=79.1499823363259, w0=72.63366336633676, w1=15.975132254921691\n",
      "SubGD iter. 415/499: loss=79.16208517089612, w0=72.62673267326745, w1=15.973006155135954\n",
      "SubGD iter. 416/499: loss=79.16154761205142, w0=72.62673267326745, w1=15.971396494414867\n",
      "SubGD iter. 417/499: loss=79.15360022377675, w0=72.63366336633676, w1=15.975865194222271\n",
      "SubGD iter. 418/499: loss=79.16570633363266, w0=72.62673267326745, w1=15.973739094436533\n",
      "SubGD iter. 419/499: loss=79.1651672164859, w0=72.62673267326745, w1=15.972129433715446\n",
      "SubGD iter. 420/499: loss=79.15721864842762, w0=72.62673267326745, w1=15.97051977299436\n",
      "SubGD iter. 421/499: loss=79.14927267137698, w0=72.63366336633676, w1=15.974988472801764\n",
      "SubGD iter. 422/499: loss=79.16137486342805, w0=72.62673267326745, w1=15.972862373016026\n",
      "SubGD iter. 423/499: loss=79.16083761027849, w0=72.62673267326745, w1=15.97125271229494\n",
      "SubGD iter. 424/499: loss=79.15289045344423, w0=72.63366336633676, w1=15.975721412102343\n",
      "SubGD iter. 425/499: loss=79.164995920781, w0=72.62673267326745, w1=15.973595312316606\n",
      "SubGD iter. 426/499: loss=79.16445710932939, w0=72.62673267326745, w1=15.971985651595519\n",
      "SubGD iter. 427/499: loss=79.15650877271153, w0=72.63366336633676, w1=15.976454351402923\n",
      "SubGD iter. 428/499: loss=79.16861751533402, w0=72.62673267326745, w1=15.974328251617186\n",
      "SubGD iter. 429/499: loss=79.1680771455803, w0=72.62673267326745, w1=15.972718590896099\n",
      "SubGD iter. 430/499: loss=79.16012762917885, w0=72.62673267326745, w1=15.971108930175012\n",
      "SubGD iter. 431/499: loss=79.15218070378502, w0=72.63366336633676, w1=15.975577629982416\n",
      "SubGD iter. 432/499: loss=79.16428552860268, w0=72.62673267326745, w1=15.973451530196678\n",
      "SubGD iter. 433/499: loss=79.16374702284618, w0=72.62673267326745, w1=15.971841869475591\n",
      "SubGD iter. 434/499: loss=79.15579891766876, w0=72.63366336633676, w1=15.976310569282996\n",
      "SubGD iter. 435/499: loss=79.16790701777211, w0=72.62673267326745, w1=15.974184469497258\n",
      "SubGD iter. 436/499: loss=79.16736695371353, w0=72.62673267326745, w1=15.972574808776171\n",
      "SubGD iter. 437/499: loss=79.1594176687525, w0=72.62673267326745, w1=15.970965148055084\n",
      "SubGD iter. 438/499: loss=79.15147097479911, w0=72.63366336633676, w1=15.975433847862488\n",
      "SubGD iter. 439/499: loss=79.16357515709763, w0=72.62673267326745, w1=15.973307748076751\n",
      "SubGD iter. 440/499: loss=79.16303695703627, w0=72.62673267326745, w1=15.971698087355664\n",
      "SubGD iter. 441/499: loss=79.15508908329927, w0=72.63366336633676, w1=15.976166787163068\n",
      "SubGD iter. 442/499: loss=79.1671965408835, w0=72.62673267326745, w1=15.97404068737733\n",
      "SubGD iter. 443/499: loss=79.16665678252004, w0=72.62673267326745, w1=15.972431026656244\n",
      "SubGD iter. 444/499: loss=79.15870772899946, w0=72.62673267326745, w1=15.970821365935157\n",
      "SubGD iter. 445/499: loss=79.15076126648651, w0=72.63366336633676, w1=15.975290065742561\n",
      "SubGD iter. 446/499: loss=79.16286480626589, w0=72.62673267326745, w1=15.973163965956823\n",
      "SubGD iter. 447/499: loss=79.16232691189965, w0=72.62673267326745, w1=15.971554305235736\n",
      "SubGD iter. 448/499: loss=79.15437926960308, w0=72.63366336633676, w1=15.97602300504314\n",
      "SubGD iter. 449/499: loss=79.16648608466815, w0=72.62673267326745, w1=15.973896905257403\n",
      "SubGD iter. 450/499: loss=79.16594663199984, w0=72.62673267326745, w1=15.972287244536316\n",
      "SubGD iter. 451/499: loss=79.15799780991969, w0=72.62673267326745, w1=15.97067758381523\n",
      "SubGD iter. 452/499: loss=79.15005157884717, w0=72.63366336633676, w1=15.975146283622633\n",
      "SubGD iter. 453/499: loss=79.16215447610742, w0=72.62673267326745, w1=15.973020183836896\n",
      "SubGD iter. 454/499: loss=79.16161688743632, w0=72.62673267326745, w1=15.971410523115809\n",
      "SubGD iter. 455/499: loss=79.15366947658022, w0=72.63366336633676, w1=15.975879222923213\n",
      "SubGD iter. 456/499: loss=79.16577564912616, w0=72.62673267326745, w1=15.973753123137476\n",
      "SubGD iter. 457/499: loss=79.16523650215298, w0=72.62673267326745, w1=15.972143462416389\n",
      "SubGD iter. 458/499: loss=79.15728791151325, w0=72.62673267326745, w1=15.970533801695302\n",
      "SubGD iter. 459/499: loss=79.14934191188117, w0=72.63366336633676, w1=15.975002501502706\n",
      "SubGD iter. 460/499: loss=79.16144416662226, w0=72.62673267326745, w1=15.972876401716968\n",
      "SubGD iter. 461/499: loss=79.1609068836463, w0=72.62673267326745, w1=15.971266740995882\n",
      "SubGD iter. 462/499: loss=79.15295970423062, w0=72.63366336633676, w1=15.975735440803286\n",
      "SubGD iter. 463/499: loss=79.16506523425745, w0=72.62673267326745, w1=15.973609341017548\n",
      "SubGD iter. 464/499: loss=79.1645263929794, w0=72.62673267326745, w1=15.971999680296461\n",
      "SubGD iter. 465/499: loss=79.1565780337801, w0=72.63366336633676, w1=15.976468380103865\n",
      "SubGD iter. 466/499: loss=79.16868683909263, w0=72.62673267326745, w1=15.974342280318128\n",
      "SubGD iter. 467/499: loss=79.16814643951248, w0=72.62673267326745, w1=15.972732619597041\n",
      "SubGD iter. 468/499: loss=79.1601969005296, w0=72.62673267326745, w1=15.971122958875954\n",
      "SubGD iter. 469/499: loss=79.15224995255433, w0=72.63366336633676, w1=15.975591658683358\n",
      "SubGD iter. 470/499: loss=79.16435484006202, w0=72.62673267326745, w1=15.97346555889762\n",
      "SubGD iter. 471/499: loss=79.16381630447911, w0=72.62673267326745, w1=15.971855898176534\n",
      "SubGD iter. 472/499: loss=79.15586817672025, w0=72.63366336633676, w1=15.976324597983938\n",
      "SubGD iter. 473/499: loss=79.16797633951364, w0=72.62673267326745, w1=15.9741984981982\n",
      "SubGD iter. 474/499: loss=79.16743624562864, w0=72.62673267326745, w1=15.972588837477113\n",
      "SubGD iter. 475/499: loss=79.15948693808618, w0=72.62673267326745, w1=15.970979176756027\n",
      "SubGD iter. 476/499: loss=79.15154022155131, w0=72.63366336633676, w1=15.97544787656343\n",
      "SubGD iter. 477/499: loss=79.1636444665399, w0=72.62673267326745, w1=15.973321776777693\n",
      "SubGD iter. 478/499: loss=79.16310623665211, w0=72.62673267326745, w1=15.971712116056606\n",
      "SubGD iter. 479/499: loss=79.15515834033368, w0=72.63366336633676, w1=15.97618081586401\n",
      "SubGD iter. 480/499: loss=79.16726586060794, w0=72.62673267326745, w1=15.974054716078273\n",
      "SubGD iter. 481/499: loss=79.16672607241809, w0=72.62673267326745, w1=15.972445055357186\n",
      "SubGD iter. 482/499: loss=79.15877699631604, w0=72.62673267326745, w1=15.970835394636099\n",
      "SubGD iter. 483/499: loss=79.15083051122163, w0=72.63366336633676, w1=15.975304094443503\n",
      "SubGD iter. 484/499: loss=79.16293411369108, w0=72.62673267326745, w1=15.973177994657766\n",
      "SubGD iter. 485/499: loss=79.16239618949841, w0=72.62673267326745, w1=15.971568333936679\n",
      "SubGD iter. 486/499: loss=79.1544485246204, w0=72.63366336633676, w1=15.976037033744083\n",
      "SubGD iter. 487/499: loss=79.16655540237556, w0=72.62673267326745, w1=15.973910933958345\n",
      "SubGD iter. 488/499: loss=79.16601591988083, w0=72.62673267326745, w1=15.972301273237258\n",
      "SubGD iter. 489/499: loss=79.15806707521922, w0=72.62673267326745, w1=15.970691612516172\n",
      "SubGD iter. 490/499: loss=79.15012082156524, w0=72.63366336633676, w1=15.975160312323576\n",
      "SubGD iter. 491/499: loss=79.16222378151555, w0=72.62673267326745, w1=15.973034212537838\n",
      "SubGD iter. 492/499: loss=79.16168616301803, w0=72.62673267326745, w1=15.971424551816751\n",
      "SubGD iter. 493/499: loss=79.15373872958047, w0=72.63366336633676, w1=15.975893251624155\n",
      "SubGD iter. 494/499: loss=79.16584496481647, w0=72.62673267326745, w1=15.973767151838418\n",
      "SubGD iter. 495/499: loss=79.16530578801688, w0=72.62673267326745, w1=15.972157491117331\n",
      "SubGD iter. 496/499: loss=79.15735717479569, w0=72.62673267326745, w1=15.970547830396244\n",
      "SubGD iter. 497/499: loss=79.14941115258215, w0=72.63366336633676, w1=15.975016530203648\n",
      "SubGD iter. 498/499: loss=79.16151347001332, w0=72.62673267326745, w1=15.97289043041791\n",
      "SubGD iter. 499/499: loss=79.16097615721092, w0=72.62673267326745, w1=15.971280769696824\n",
      "SubGD: execution time=0.047 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bb438087b84a17a00e960b08b916db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic SubGradient Descent algorithm (SubSGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        # ***************************************************\n",
    "        for batch_y, batch_tx in batch_iter(y, tx, batch_size):\n",
    "            subgrad = compute_subgradient_mae(batch_y, batch_tx, w)\n",
    "            loss = compute_loss(batch_y, batch_tx, w)\n",
    "        w = w - gamma * subgrad\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=1431.098106900423, w0=0.7, w1=-0.734114323000989\n",
      "SubSGD iter. 1/499: loss=1603.769819355591, w0=1.4, w1=-1.1743095777079602\n",
      "SubSGD iter. 2/499: loss=1084.7014987667008, w0=2.0999999999999996, w1=-2.38573246563414\n",
      "SubSGD iter. 3/499: loss=2381.965029297282, w0=2.8, w1=-2.1869715998156156\n",
      "SubSGD iter. 4/499: loss=2014.493989119611, w0=3.5, w1=-2.714160238562843\n",
      "SubSGD iter. 5/499: loss=1560.221645655407, w0=4.2, w1=-2.7279154345383336\n",
      "SubSGD iter. 6/499: loss=2293.1075161123117, w0=4.9, w1=-3.1100414190886685\n",
      "SubSGD iter. 7/499: loss=949.523893731089, w0=5.6000000000000005, w1=-3.9286997888942965\n",
      "SubSGD iter. 8/499: loss=2683.926674468958, w0=6.300000000000001, w1=-3.9023271382694755\n",
      "SubSGD iter. 9/499: loss=3310.2862918666924, w0=7.000000000000001, w1=-3.4521473920631816\n",
      "SubSGD iter. 10/499: loss=2081.8181714205903, w0=7.700000000000001, w1=-3.8342733766135164\n",
      "SubSGD iter. 11/499: loss=1746.0354218728432, w0=8.4, w1=-4.0391068964887396\n",
      "SubSGD iter. 12/499: loss=1183.0342751918886, w0=9.1, w1=-4.319035888925203\n",
      "SubSGD iter. 13/499: loss=1543.9343866018799, w0=9.799999999999999, w1=-4.8462245276724305\n",
      "SubSGD iter. 14/499: loss=4564.7363926327735, w0=10.499999999999998, w1=-3.640208237901984\n",
      "SubSGD iter. 15/499: loss=3979.173649800516, w0=11.199999999999998, w1=-2.556332841210682\n",
      "SubSGD iter. 16/499: loss=4068.2964763479467, w0=11.899999999999997, w1=-1.3503165514402349\n",
      "SubSGD iter. 17/499: loss=1794.3771358870356, w0=12.599999999999996, w1=-1.47733099666826\n",
      "SubSGD iter. 18/499: loss=1277.3071018051317, w0=13.299999999999995, w1=-2.216663796112204\n",
      "SubSGD iter. 19/499: loss=926.6671760697359, w0=13.999999999999995, w1=-2.8377153696827975\n",
      "SubSGD iter. 20/499: loss=1015.8471053431194, w0=14.699999999999994, w1=-3.277403774767982\n",
      "SubSGD iter. 21/499: loss=2043.9813759340072, w0=15.399999999999993, w1=-3.0482820824812236\n",
      "SubSGD iter. 22/499: loss=3292.226188840358, w0=16.099999999999994, w1=-2.3301187584500354\n",
      "SubSGD iter. 23/499: loss=2278.866403129382, w0=16.799999999999994, w1=-1.951578975093304\n",
      "SubSGD iter. 24/499: loss=2881.4698401702262, w0=17.499999999999993, w1=-1.3983730590171906\n",
      "SubSGD iter. 25/499: loss=3292.739878082624, w0=18.199999999999992, w1=-0.3057485446913961\n",
      "SubSGD iter. 26/499: loss=2661.51321879, w0=18.89999999999999, w1=0.535441623533247\n",
      "SubSGD iter. 27/499: loss=1926.104939310935, w0=19.59999999999999, w1=0.7008944154658727\n",
      "SubSGD iter. 28/499: loss=917.3275217247534, w0=20.29999999999999, w1=0.7572040305111762\n",
      "SubSGD iter. 29/499: loss=1246.3025294958356, w0=20.99999999999999, w1=0.42084107283509953\n",
      "SubSGD iter. 30/499: loss=2045.5768871773082, w0=21.69999999999999, w1=1.36775333457753\n",
      "SubSGD iter. 31/499: loss=2262.1265128927685, w0=22.399999999999988, w1=2.019810232019985\n",
      "SubSGD iter. 32/499: loss=1231.204455489521, w0=23.099999999999987, w1=1.7643783509184143\n",
      "SubSGD iter. 33/499: loss=1324.9696028334663, w0=23.799999999999986, w1=2.312772854676225\n",
      "SubSGD iter. 34/499: loss=1367.3671886335055, w0=24.499999999999986, w1=2.5630539711382814\n",
      "SubSGD iter. 35/499: loss=734.7575751901796, w0=25.199999999999985, w1=1.5361217735457477\n",
      "SubSGD iter. 36/499: loss=2731.5988403866695, w0=25.899999999999984, w1=2.5488001148985147\n",
      "SubSGD iter. 37/499: loss=845.2923263827072, w0=26.599999999999984, w1=2.4679858094098037\n",
      "SubSGD iter. 38/499: loss=953.8625840414539, w0=27.299999999999983, w1=2.646337930789618\n",
      "SubSGD iter. 39/499: loss=1403.2643295424302, w0=27.999999999999982, w1=2.9164763810792884\n",
      "SubSGD iter. 40/499: loss=1131.840624385553, w0=28.69999999999998, w1=3.2517044363825436\n",
      "SubSGD iter. 41/499: loss=868.2078398626765, w0=29.39999999999998, w1=2.7245157976353163\n",
      "SubSGD iter. 42/499: loss=1919.8315826267738, w0=30.09999999999998, w1=3.337508294818876\n",
      "SubSGD iter. 43/499: loss=335.8856668808262, w0=30.79999999999998, w1=2.518849925013248\n",
      "SubSGD iter. 44/499: loss=1588.0392561978003, w0=31.49999999999998, w1=2.7631626487223824\n",
      "SubSGD iter. 45/499: loss=741.2169216453724, w0=32.19999999999998, w1=2.2359740099751555\n",
      "SubSGD iter. 46/499: loss=1691.9898460303789, w0=32.899999999999984, w1=2.7769310619462977\n",
      "SubSGD iter. 47/499: loss=1563.7495414272548, w0=33.59999999999999, w1=3.419860760710093\n",
      "SubSGD iter. 48/499: loss=1510.2528196536289, w0=34.29999999999999, w1=4.25319834326967\n",
      "SubSGD iter. 49/499: loss=1068.6663658892096, w0=34.99999999999999, w1=4.954132340704422\n",
      "SubSGD iter. 50/499: loss=278.4787882296487, w0=35.699999999999996, w1=4.406970038470552\n",
      "SubSGD iter. 51/499: loss=145.2008958963765, w0=36.4, w1=3.7263708608144697\n",
      "SubSGD iter. 52/499: loss=1152.3873403394675, w0=37.1, w1=3.9227154543316978\n",
      "SubSGD iter. 53/499: loss=1027.26950064964, w0=37.800000000000004, w1=4.036535781146011\n",
      "SubSGD iter. 54/499: loss=195.98947010961473, w0=38.50000000000001, w1=3.134903516733253\n",
      "SubSGD iter. 55/499: loss=228.57509853810254, w0=39.20000000000001, w1=2.7238283321910273\n",
      "SubSGD iter. 56/499: loss=1271.1246267471367, w0=39.90000000000001, w1=3.603000644421834\n",
      "SubSGD iter. 57/499: loss=298.63387892749915, w0=40.600000000000016, w1=2.99923457445532\n",
      "SubSGD iter. 58/499: loss=391.1720880997247, w0=41.30000000000002, w1=2.3125399389491834\n",
      "SubSGD iter. 59/499: loss=121.33915714444741, w0=42.00000000000002, w1=1.80403882120935\n",
      "SubSGD iter. 60/499: loss=1138.4856652363637, w0=42.700000000000024, w1=2.4469685199731455\n",
      "SubSGD iter. 61/499: loss=34.653631009807214, w0=43.40000000000003, w1=1.3571734968999252\n",
      "SubSGD iter. 62/499: loss=107.22787304339782, w0=44.10000000000003, w1=1.0719990023506307\n",
      "SubSGD iter. 63/499: loss=963.2045378562308, w0=44.80000000000003, w1=1.8333559529697\n",
      "SubSGD iter. 64/499: loss=77.2066713771654, w0=45.500000000000036, w1=1.2205577819682878\n",
      "SubSGD iter. 65/499: loss=926.9172833891456, w0=46.20000000000004, w1=1.744738333420006\n",
      "SubSGD iter. 66/499: loss=512.3723498031119, w0=46.90000000000004, w1=1.8880689240145223\n",
      "SubSGD iter. 67/499: loss=358.56207254523247, w0=47.600000000000044, w1=1.940229269544233\n",
      "SubSGD iter. 68/499: loss=370.78668130137544, w0=48.30000000000005, w1=2.0505293030050247\n",
      "SubSGD iter. 69/499: loss=62.212055443256425, w0=49.00000000000005, w1=2.036774107029534\n",
      "SubSGD iter. 70/499: loss=190.35376711189403, w0=49.70000000000005, w1=1.8319405871543109\n",
      "SubSGD iter. 71/499: loss=28.34737217697184, w0=50.400000000000055, w1=1.279969155216632\n",
      "SubSGD iter. 72/499: loss=301.52450989677396, w0=51.10000000000006, w1=1.8283636589744428\n",
      "SubSGD iter. 73/499: loss=913.7281285355998, w0=51.80000000000006, w1=3.0343799487448897\n",
      "SubSGD iter. 74/499: loss=648.5679192895145, w0=52.500000000000064, w1=4.09078118012378\n",
      "SubSGD iter. 75/499: loss=257.0757367451221, w0=53.20000000000007, w1=4.355566289314548\n",
      "SubSGD iter. 76/499: loss=502.9738231445797, w0=53.90000000000007, w1=5.260741392501611\n",
      "SubSGD iter. 77/499: loss=317.9946446558416, w0=54.60000000000007, w1=5.2980287041194805\n",
      "SubSGD iter. 78/499: loss=568.0436134646385, w0=55.300000000000075, w1=5.645995750509895\n",
      "SubSGD iter. 79/499: loss=0.9168410161759228, w0=54.60000000000007, w1=6.326594928165978\n",
      "SubSGD iter. 80/499: loss=487.5857343161904, w0=55.300000000000075, w1=6.570907651875112\n",
      "SubSGD iter. 81/499: loss=374.8589599351384, w0=56.00000000000008, w1=7.037489777841687\n",
      "SubSGD iter. 82/499: loss=501.3666615400603, w0=56.70000000000008, w1=7.477414220725869\n",
      "SubSGD iter. 83/499: loss=53.52337125979322, w0=57.400000000000084, w1=7.127077287357478\n",
      "SubSGD iter. 84/499: loss=55.18840607995848, w0=58.10000000000009, w1=6.942916509039158\n",
      "SubSGD iter. 85/499: loss=0.17075762140028192, w0=57.400000000000084, w1=8.06884892254033\n",
      "SubSGD iter. 86/499: loss=237.30550206870043, w0=58.10000000000009, w1=8.234301714472956\n",
      "SubSGD iter. 87/499: loss=12.280479622618138, w0=58.80000000000009, w1=7.849017574144828\n",
      "SubSGD iter. 88/499: loss=2.205000329367079, w0=59.50000000000009, w1=7.340516456404994\n",
      "SubSGD iter. 89/499: loss=267.58895150564695, w0=60.200000000000095, w1=7.606000158629224\n",
      "SubSGD iter. 90/499: loss=166.18583311759966, w0=60.9000000000001, w1=7.632372809254045\n",
      "SubSGD iter. 91/499: loss=256.3800354257168, w0=61.6000000000001, w1=8.465710391813623\n",
      "SubSGD iter. 92/499: loss=5.525980041702052, w0=62.300000000000104, w1=7.80882942406066\n",
      "SubSGD iter. 93/499: loss=5.9916608170125025, w0=63.00000000000011, w1=7.369141018975475\n",
      "SubSGD iter. 94/499: loss=25.007169560947702, w0=63.70000000000011, w1=7.164307499100253\n",
      "SubSGD iter. 95/499: loss=109.17500800772567, w0=64.4000000000001, w1=7.542847282456984\n",
      "SubSGD iter. 96/499: loss=3806.9374881363838, w0=65.10000000000011, w1=4.772547585567995\n",
      "SubSGD iter. 97/499: loss=5.989477952334439, w0=65.80000000000011, w1=4.406626854837598\n",
      "SubSGD iter. 98/499: loss=29.836635318475906, w0=65.10000000000011, w1=5.308259119250356\n",
      "SubSGD iter. 99/499: loss=76.65664595456333, w0=65.80000000000011, w1=5.451589709844872\n",
      "SubSGD iter. 100/499: loss=216.66853817740784, w0=66.50000000000011, w1=6.246759434962219\n",
      "SubSGD iter. 101/499: loss=63.660964071395696, w0=67.20000000000012, w1=6.59047205614561\n",
      "SubSGD iter. 102/499: loss=138.91863708630794, w0=67.90000000000012, w1=7.674347452836912\n",
      "SubSGD iter. 103/499: loss=17.889601428108712, w0=67.20000000000012, w1=8.858349653230803\n",
      "SubSGD iter. 104/499: loss=9.811874445059722, w0=66.50000000000011, w1=9.410321085168482\n",
      "SubSGD iter. 105/499: loss=397.4564645280447, w0=67.20000000000012, w1=10.535451045298789\n",
      "SubSGD iter. 106/499: loss=4.41923224277901, w0=66.50000000000011, w1=10.946526229841014\n",
      "SubSGD iter. 107/499: loss=8.919814938975131, w0=67.20000000000012, w1=11.893438491583444\n",
      "SubSGD iter. 108/499: loss=18.577884897141416, w0=67.90000000000012, w1=11.793161392343235\n",
      "SubSGD iter. 109/499: loss=57.14725576408946, w0=68.60000000000012, w1=12.626498974902812\n",
      "SubSGD iter. 110/499: loss=17.43942085859162, w0=69.30000000000013, w1=12.828935864943812\n",
      "SubSGD iter. 111/499: loss=12.23703818896638, w0=68.60000000000012, w1=13.451722271764105\n",
      "SubSGD iter. 112/499: loss=3.5387961523017766, w0=67.90000000000012, w1=13.86279745630633\n",
      "SubSGD iter. 113/499: loss=17.64369560576733, w0=68.60000000000012, w1=13.509681704739016\n",
      "SubSGD iter. 114/499: loss=0.6450055297447105, w0=67.90000000000012, w1=13.331329583359201\n",
      "SubSGD iter. 115/499: loss=0.002479220555998561, w0=68.60000000000012, w1=12.24153456028598\n",
      "SubSGD iter. 116/499: loss=96.7329594181471, w0=69.30000000000013, w1=12.519661529087669\n",
      "SubSGD iter. 117/499: loss=6.36898640494731, w0=70.00000000000013, w1=11.841314533113126\n",
      "SubSGD iter. 118/499: loss=4.258695419758921, w0=69.30000000000013, w1=11.642553667294601\n",
      "SubSGD iter. 119/499: loss=7.711515893367058, w0=68.60000000000012, w1=12.450667408336534\n",
      "SubSGD iter. 120/499: loss=4.657811388249529, w0=69.30000000000013, w1=12.492993964940025\n",
      "SubSGD iter. 121/499: loss=5196.705300295258, w0=70.00000000000013, w1=9.722694268051036\n",
      "SubSGD iter. 122/499: loss=23.058787462347595, w0=70.70000000000013, w1=9.738001934763172\n",
      "SubSGD iter. 123/499: loss=53.43187041762093, w0=71.40000000000013, w1=10.571339517322748\n",
      "SubSGD iter. 124/499: loss=27.646641390990684, w0=72.10000000000014, w1=10.608626828940618\n",
      "SubSGD iter. 125/499: loss=8.622795572380136, w0=71.40000000000013, w1=10.68944113442933\n",
      "SubSGD iter. 126/499: loss=11.797270060382042, w0=72.10000000000014, w1=11.21749694993998\n",
      "SubSGD iter. 127/499: loss=4.795209085408502, w0=71.40000000000013, w1=11.648507634688594\n",
      "SubSGD iter. 128/499: loss=0.0786894611100753, w0=72.10000000000014, w1=11.272921796402024\n",
      "SubSGD iter. 129/499: loss=39.58909308021521, w0=72.80000000000014, w1=12.129143848906562\n",
      "SubSGD iter. 130/499: loss=20.25264492050117, w0=73.50000000000014, w1=11.779205917426244\n",
      "SubSGD iter. 131/499: loss=1.6330736620774797, w0=72.80000000000014, w1=11.736879360822753\n",
      "SubSGD iter. 132/499: loss=36.772495631773566, w0=73.50000000000014, w1=12.455042684853941\n",
      "SubSGD iter. 133/499: loss=0.42592731617434804, w0=72.80000000000014, w1=12.82096341558434\n",
      "SubSGD iter. 134/499: loss=0.15540118784838183, w0=72.10000000000014, w1=13.517548166825103\n",
      "SubSGD iter. 135/499: loss=23.671524923859483, w0=72.80000000000014, w1=12.778215367381158\n",
      "SubSGD iter. 136/499: loss=1.8907346501257496, w0=72.10000000000014, w1=12.442987312077904\n",
      "SubSGD iter. 137/499: loss=3.318074648276074, w0=72.80000000000014, w1=11.888880238081322\n",
      "SubSGD iter. 138/499: loss=27.945957511537635, w0=72.10000000000014, w1=12.23405732580632\n",
      "SubSGD iter. 139/499: loss=4.669093980559496, w0=72.80000000000014, w1=11.19654313199278\n",
      "SubSGD iter. 140/499: loss=7.308965172704965, w0=72.10000000000014, w1=11.3807039103111\n",
      "SubSGD iter. 141/499: loss=0.09989568774862682, w0=71.40000000000013, w1=11.75628974859767\n",
      "SubSGD iter. 142/499: loss=78.53395103021127, w0=72.10000000000014, w1=12.000602472306804\n",
      "SubSGD iter. 143/499: loss=10.05479256151902, w0=72.80000000000014, w1=12.250200934993982\n",
      "SubSGD iter. 144/499: loss=91.20098747526721, w0=72.10000000000014, w1=12.370092748482314\n",
      "SubSGD iter. 145/499: loss=27.88032233458955, w0=72.80000000000014, w1=12.9847537296127\n",
      "SubSGD iter. 146/499: loss=16.14790498665812, w0=72.10000000000014, w1=13.71886805261369\n",
      "SubSGD iter. 147/499: loss=5.07994085280347, w0=72.80000000000014, w1=14.228053896559942\n",
      "SubSGD iter. 148/499: loss=19.19358165871006, w0=72.10000000000014, w1=14.472080721269093\n",
      "SubSGD iter. 149/499: loss=9.1158617942772, w0=72.80000000000014, w1=15.26725044638644\n",
      "SubSGD iter. 150/499: loss=29.211824681922128, w0=73.50000000000014, w1=15.026270531719792\n",
      "SubSGD iter. 151/499: loss=13.501624277139136, w0=72.80000000000014, w1=15.449509956492307\n",
      "SubSGD iter. 152/499: loss=15.918468645549355, w0=72.10000000000014, w1=16.28554881376512\n",
      "SubSGD iter. 153/499: loss=13.227591572032322, w0=72.80000000000014, w1=16.451001605697748\n",
      "SubSGD iter. 154/499: loss=3.9096848925206, w0=73.50000000000014, w1=17.067388554534997\n",
      "SubSGD iter. 155/499: loss=0.1787314416028362, w0=72.80000000000014, w1=17.17756267141574\n",
      "SubSGD iter. 156/499: loss=2.099937939993726, w0=73.50000000000014, w1=17.15359683161265\n",
      "SubSGD iter. 157/499: loss=43.6873296110356, w0=72.80000000000014, w1=15.98526603109518\n",
      "SubSGD iter. 158/499: loss=6.957728253225015, w0=72.10000000000014, w1=16.490283762919503\n",
      "SubSGD iter. 159/499: loss=14.469564674785472, w0=72.80000000000014, w1=17.50296210427227\n",
      "SubSGD iter. 160/499: loss=0.016800310625358278, w0=72.10000000000014, w1=16.49052376640585\n",
      "SubSGD iter. 161/499: loss=6.938455405104027, w0=72.80000000000014, w1=16.918040851623267\n",
      "SubSGD iter. 162/499: loss=8.519984401521995, w0=72.10000000000014, w1=16.012865748436205\n",
      "SubSGD iter. 163/499: loss=20.620727808556666, w0=72.80000000000014, w1=16.16575950555079\n",
      "SubSGD iter. 164/499: loss=8.808075436118768, w0=72.10000000000014, w1=15.464825508116036\n",
      "SubSGD iter. 165/499: loss=23.460875756414666, w0=72.80000000000014, w1=16.01803142419215\n",
      "SubSGD iter. 166/499: loss=0.4273687298820478, w0=72.10000000000014, w1=16.388299514720945\n",
      "SubSGD iter. 167/499: loss=0.3542266585499364, w0=71.40000000000013, w1=16.3818716338426\n",
      "SubSGD iter. 168/499: loss=0.30655864771409974, w0=72.10000000000014, w1=15.950860949093986\n",
      "SubSGD iter. 169/499: loss=8.220561839919629, w0=72.80000000000014, w1=16.378378034311403\n",
      "SubSGD iter. 170/499: loss=37.29173148883877, w0=72.10000000000014, w1=16.6635525288607\n",
      "SubSGD iter. 171/499: loss=0.5465025709329288, w0=72.80000000000014, w1=17.17273837280695\n",
      "SubSGD iter. 172/499: loss=0.009912827122796697, w0=73.50000000000014, w1=16.967904852931728\n",
      "SubSGD iter. 173/499: loss=0.900726037872643, w0=74.20000000000014, w1=16.943939013128638\n",
      "SubSGD iter. 174/499: loss=7.235290223622341, w0=74.90000000000015, w1=16.60757605545256\n",
      "SubSGD iter. 175/499: loss=53.00751566697799, w0=74.20000000000014, w1=17.288175233108646\n",
      "SubSGD iter. 176/499: loss=61.05882806976274, w0=74.90000000000015, w1=17.632643479979112\n",
      "SubSGD iter. 177/499: loss=50.90204402339885, w0=74.20000000000014, w1=17.209102226925097\n",
      "SubSGD iter. 178/499: loss=6694.681056759916, w0=74.90000000000015, w1=14.438802530036108\n",
      "SubSGD iter. 179/499: loss=0.2957685610091681, w0=74.20000000000014, w1=14.791918281603422\n",
      "SubSGD iter. 180/499: loss=3.2401601475832087, w0=73.50000000000014, w1=15.576151009642746\n",
      "SubSGD iter. 181/499: loss=5.023201706824331, w0=72.80000000000014, w1=15.776900546691998\n",
      "SubSGD iter. 182/499: loss=0.9966455132951463, w0=73.50000000000014, w1=16.895210767303478\n",
      "SubSGD iter. 183/499: loss=0.0008714143812962732, w0=72.80000000000014, w1=16.729404507735982\n",
      "SubSGD iter. 184/499: loss=1.208563139082568, w0=72.10000000000014, w1=17.537518248777914\n",
      "SubSGD iter. 185/499: loss=0.285339960226117, w0=71.40000000000013, w1=17.495191692174423\n",
      "SubSGD iter. 186/499: loss=0.0994367212495391, w0=72.10000000000014, w1=17.055503287089238\n",
      "SubSGD iter. 187/499: loss=7.293175480919241, w0=72.80000000000014, w1=17.773666611120426\n",
      "SubSGD iter. 188/499: loss=0.6412014602717634, w0=72.10000000000014, w1=18.47717152951129\n",
      "SubSGD iter. 189/499: loss=0.32987596664559626, w0=71.40000000000013, w1=18.434844972907797\n",
      "SubSGD iter. 190/499: loss=0.15853201635880135, w0=70.70000000000013, w1=18.939862704732118\n",
      "SubSGD iter. 191/499: loss=5.408143598820727, w0=71.40000000000013, w1=19.21000115502179\n",
      "SubSGD iter. 192/499: loss=0.4440005826585882, w0=72.10000000000014, w1=19.862058052464246\n",
      "SubSGD iter. 193/499: loss=1.6358691921875137, w0=72.80000000000014, w1=19.49178996193545\n",
      "SubSGD iter. 194/499: loss=19.01185480362148, w0=73.50000000000014, w1=20.73110626291345\n",
      "SubSGD iter. 195/499: loss=4.992357536709865, w0=74.20000000000014, w1=20.54764048386303\n",
      "SubSGD iter. 196/499: loss=3.8772368889562454, w0=73.50000000000014, w1=19.91536605538134\n",
      "SubSGD iter. 197/499: loss=21.67037256519672, w0=72.80000000000014, w1=19.560338577851514\n",
      "SubSGD iter. 198/499: loss=15.567015583903206, w0=73.50000000000014, w1=20.68546853798182\n",
      "SubSGD iter. 199/499: loss=15.616830688529072, w0=74.20000000000014, w1=21.125392980866\n",
      "SubSGD iter. 200/499: loss=54.8099585959885, w0=74.90000000000015, w1=19.94139078047211\n",
      "SubSGD iter. 201/499: loss=27.937998187529193, w0=74.20000000000014, w1=19.606162725168854\n",
      "SubSGD iter. 202/499: loss=0.9255488435853271, w0=74.90000000000015, w1=19.802682807947356\n",
      "SubSGD iter. 203/499: loss=13.191611248250146, w0=74.20000000000014, w1=19.354023769162644\n",
      "SubSGD iter. 204/499: loss=17.68174709673395, w0=74.90000000000015, w1=18.799916695166065\n",
      "SubSGD iter. 205/499: loss=25.77687478586362, w0=75.60000000000015, w1=18.27272805641884\n",
      "SubSGD iter. 206/499: loss=37.70027509607277, w0=74.90000000000015, w1=17.21481274959128\n",
      "SubSGD iter. 207/499: loss=2.672140993248215, w0=74.20000000000014, w1=17.75782921095638\n",
      "SubSGD iter. 208/499: loss=21.87174506276665, w0=73.50000000000014, w1=16.852654107769318\n",
      "SubSGD iter. 209/499: loss=0.8829781465421309, w0=72.80000000000014, w1=16.322953133707202\n",
      "SubSGD iter. 210/499: loss=3.6571861492330187, w0=73.50000000000014, w1=16.139487354656783\n",
      "SubSGD iter. 211/499: loss=2.21166247833585, w0=72.80000000000014, w1=15.29829718643214\n",
      "SubSGD iter. 212/499: loss=6.552909420771872, w0=72.10000000000014, w1=16.001802104823003\n",
      "SubSGD iter. 213/499: loss=0.1391239081300207, w0=72.80000000000014, w1=16.053962450352714\n",
      "SubSGD iter. 214/499: loss=33.57436321805663, w0=73.50000000000014, w1=16.3320894191544\n",
      "SubSGD iter. 215/499: loss=0.8209116114205431, w0=72.80000000000014, w1=16.102967726867643\n",
      "SubSGD iter. 216/499: loss=23.4998271967578, w0=73.50000000000014, w1=16.643924778838784\n",
      "SubSGD iter. 217/499: loss=3.670296269464497, w0=72.80000000000014, w1=15.802734610614142\n",
      "SubSGD iter. 218/499: loss=0.0776706070575067, w0=73.50000000000014, w1=16.68190692284495\n",
      "SubSGD iter. 219/499: loss=0.9510257674211124, w0=72.80000000000014, w1=15.141844584457763\n",
      "SubSGD iter. 220/499: loss=7.695305971646101, w0=72.10000000000014, w1=15.754642755459175\n",
      "SubSGD iter. 221/499: loss=3.9562798412403084, w0=72.80000000000014, w1=16.549812480576524\n",
      "SubSGD iter. 222/499: loss=28.89368304749357, w0=73.50000000000014, w1=15.195855586543296\n",
      "SubSGD iter. 223/499: loss=38.41888427074776, w0=72.80000000000014, w1=15.47578457897976\n",
      "SubSGD iter. 224/499: loss=59.74960595946118, w0=73.50000000000014, w1=14.856643423565377\n",
      "SubSGD iter. 225/499: loss=2.210770119625895, w0=74.20000000000014, w1=15.30682316977167\n",
      "SubSGD iter. 226/499: loss=0.29530261354821036, w0=74.90000000000015, w1=15.395350683260796\n",
      "SubSGD iter. 227/499: loss=0.17849196922730995, w0=74.20000000000014, w1=14.562013100701218\n",
      "SubSGD iter. 228/499: loss=21.105946914756537, w0=74.90000000000015, w1=14.675833427515531\n",
      "SubSGD iter. 229/499: loss=0.033564125048050515, w0=75.60000000000015, w1=15.509171010075107\n",
      "SubSGD iter. 230/499: loss=1.9653657082062075, w0=74.90000000000015, w1=16.303540354565886\n",
      "SubSGD iter. 231/499: loss=5.904247406581054, w0=74.20000000000014, w1=16.65387728793428\n",
      "SubSGD iter. 232/499: loss=35.42078214798159, w0=73.50000000000014, w1=16.87113429211403\n",
      "SubSGD iter. 233/499: loss=11.363548402468087, w0=72.80000000000014, w1=15.965959188926965\n",
      "SubSGD iter. 234/499: loss=15.99592899725925, w0=72.10000000000014, w1=16.588745595747255\n",
      "SubSGD iter. 235/499: loss=8.924600734822361, w0=72.80000000000014, w1=15.817922529679068\n",
      "SubSGD iter. 236/499: loss=0.07033427877279001, w0=73.50000000000014, w1=16.697094841909873\n",
      "SubSGD iter. 237/499: loss=23.460584232249065, w0=74.20000000000014, w1=16.810915168724186\n",
      "SubSGD iter. 238/499: loss=7.017280275055242, w0=73.50000000000014, w1=16.995075947042505\n",
      "SubSGD iter. 239/499: loss=41.2680119705594, w0=72.80000000000014, w1=17.2802504415918\n",
      "SubSGD iter. 240/499: loss=13.167234224269045, w0=72.10000000000014, w1=17.524277266300953\n",
      "SubSGD iter. 241/499: loss=76.15484137140422, w0=71.40000000000013, w1=17.538032462276444\n",
      "SubSGD iter. 242/499: loss=0.12850823391223615, w0=70.70000000000013, w1=17.738781999325695\n",
      "SubSGD iter. 243/499: loss=0.4347859740605676, w0=71.40000000000013, w1=17.035277080934833\n",
      "SubSGD iter. 244/499: loss=0.18694331072877157, w0=70.70000000000013, w1=17.43071387287784\n",
      "SubSGD iter. 245/499: loss=1.6213041043049947, w0=71.40000000000013, w1=16.61205550307221\n",
      "SubSGD iter. 246/499: loss=6745.359730186342, w0=72.10000000000014, w1=13.84175580618322\n",
      "SubSGD iter. 247/499: loss=12.629449484875654, w0=72.80000000000014, w1=14.48790303957044\n",
      "SubSGD iter. 248/499: loss=16.035663129902314, w0=72.10000000000014, w1=14.770450858656666\n",
      "SubSGD iter. 249/499: loss=2.001338129042375, w0=71.40000000000013, w1=14.971200395705917\n",
      "SubSGD iter. 250/499: loss=0.12815706820559855, w0=72.10000000000014, w1=16.029115702533474\n",
      "SubSGD iter. 251/499: loss=1.7669236797109895, w0=71.40000000000013, w1=16.42455249447648\n",
      "SubSGD iter. 252/499: loss=44.61654726351306, w0=72.10000000000014, w1=16.620897087993708\n",
      "SubSGD iter. 253/499: loss=1.240578128958332, w0=71.40000000000013, w1=15.528272573667913\n",
      "SubSGD iter. 254/499: loss=7.590298806137833, w0=72.10000000000014, w1=15.344806794617494\n",
      "SubSGD iter. 255/499: loss=13.002984353123072, w0=72.80000000000014, w1=16.076771388125128\n",
      "SubSGD iter. 256/499: loss=25.120543556682208, w0=73.50000000000014, w1=16.739915705168176\n",
      "SubSGD iter. 257/499: loss=0.10625906761378295, w0=74.20000000000014, w1=15.838283440755418\n",
      "SubSGD iter. 258/499: loss=30.864503172002557, w0=74.90000000000015, w1=15.456157456205084\n",
      "SubSGD iter. 259/499: loss=25.003115759250143, w0=74.20000000000014, w1=15.576662007684126\n",
      "SubSGD iter. 260/499: loss=0.0550250111817924, w0=74.90000000000015, w1=16.694972228295608\n",
      "SubSGD iter. 261/499: loss=16.719067589155806, w0=75.60000000000015, w1=15.34101533426238\n",
      "SubSGD iter. 262/499: loss=0.13995644075494132, w0=74.90000000000015, w1=13.800952995875194\n",
      "SubSGD iter. 263/499: loss=1.270033323574826, w0=75.60000000000015, w1=13.464590038199118\n",
      "SubSGD iter. 264/499: loss=17.156755379411965, w0=74.90000000000015, w1=14.366222302611876\n",
      "SubSGD iter. 265/499: loss=5.5207492836171355, w0=75.60000000000015, w1=15.098186896119511\n",
      "SubSGD iter. 266/499: loss=8.371084012654862, w0=76.30000000000015, w1=15.363670598343742\n",
      "SubSGD iter. 267/499: loss=4.054763246369176, w0=75.60000000000015, w1=16.15803994283452\n",
      "SubSGD iter. 268/499: loss=8.00492331431124, w0=76.30000000000015, w1=16.77103244001808\n",
      "SubSGD iter. 269/499: loss=33.579514744707375, w0=75.60000000000015, w1=15.687157043326778\n",
      "SubSGD iter. 270/499: loss=0.7747478894377504, w0=74.90000000000015, w1=14.568846822715296\n",
      "SubSGD iter. 271/499: loss=92.24482469731433, w0=74.20000000000014, w1=14.512537207669991\n",
      "SubSGD iter. 272/499: loss=10.320109092991343, w0=73.50000000000014, w1=14.157509730140166\n",
      "SubSGD iter. 273/499: loss=5.441554468349428, w0=74.20000000000014, w1=15.275819950751648\n",
      "SubSGD iter. 274/499: loss=6.961932445838648, w0=73.50000000000014, w1=15.701606098042388\n",
      "SubSGD iter. 275/499: loss=11.585123331823787, w0=72.80000000000014, w1=16.326422197853333\n",
      "SubSGD iter. 276/499: loss=27.507720259172114, w0=73.50000000000014, w1=15.799233559106106\n",
      "SubSGD iter. 277/499: loss=21.194669511699782, w0=72.80000000000014, w1=15.949690235557235\n",
      "SubSGD iter. 278/499: loss=2.8232773135254754, w0=73.50000000000014, w1=16.199288698244413\n",
      "SubSGD iter. 279/499: loss=12.40633930473601, w0=74.20000000000014, w1=16.352182455358996\n",
      "SubSGD iter. 280/499: loss=0.9946837928066614, w0=73.50000000000014, w1=16.462356572239738\n",
      "SubSGD iter. 281/499: loss=3.348542478036445, w0=74.20000000000014, w1=16.928938698206313\n",
      "SubSGD iter. 282/499: loss=1.671962978240393, w0=73.50000000000014, w1=15.81062847759483\n",
      "SubSGD iter. 283/499: loss=41.5490416348829, w0=72.80000000000014, w1=15.549916256212967\n",
      "SubSGD iter. 284/499: loss=4.252604322039679, w0=72.10000000000014, w1=16.3580299972549\n",
      "SubSGD iter. 285/499: loss=0.46637802266723927, w0=71.40000000000013, w1=15.516839829030257\n",
      "SubSGD iter. 286/499: loss=0.6470375547902214, w0=70.70000000000013, w1=16.335498198835886\n",
      "SubSGD iter. 287/499: loss=13.52212643958324, w0=71.40000000000013, w1=16.303069191068527\n",
      "SubSGD iter. 288/499: loss=0.047010618491628, w0=70.70000000000013, w1=16.728855338359267\n",
      "SubSGD iter. 289/499: loss=5.406265241705684, w0=71.40000000000013, w1=16.628578239119058\n",
      "SubSGD iter. 290/499: loss=44.07759370949916, w0=72.10000000000014, w1=16.824922832636286\n",
      "SubSGD iter. 291/499: loss=0.6641161152025521, w0=72.80000000000014, w1=17.20346261599302\n",
      "SubSGD iter. 292/499: loss=10.696397341939395, w0=72.10000000000014, w1=17.75062491822689\n",
      "SubSGD iter. 293/499: loss=2.1748255009534154, w0=71.40000000000013, w1=17.131491522282225\n",
      "SubSGD iter. 294/499: loss=0.023653700894541475, w0=72.10000000000014, w1=16.69180311719704\n",
      "SubSGD iter. 295/499: loss=11.981758631764498, w0=71.40000000000013, w1=15.63540188581815\n",
      "SubSGD iter. 296/499: loss=1.3209208876236902, w0=70.70000000000013, w1=16.205362010354136\n",
      "SubSGD iter. 297/499: loss=2.1350918257274434, w0=71.40000000000013, w1=16.095187893473394\n",
      "SubSGD iter. 298/499: loss=65.51783352495028, w0=70.70000000000013, w1=16.215079706961724\n",
      "SubSGD iter. 299/499: loss=16.893003865505392, w0=71.40000000000013, w1=16.411599789740226\n",
      "SubSGD iter. 300/499: loss=56.57603467410645, w0=72.10000000000014, w1=15.672266990296283\n",
      "SubSGD iter. 301/499: loss=10.93424198970962, w0=71.40000000000013, w1=16.508305847569098\n",
      "SubSGD iter. 302/499: loss=13.74244724575779, w0=72.10000000000014, w1=16.523613514281234\n",
      "SubSGD iter. 303/499: loss=3.9797883028161873, w0=72.80000000000014, w1=16.793751964570905\n",
      "SubSGD iter. 304/499: loss=13.887187460496712, w0=72.10000000000014, w1=15.431000569179158\n",
      "SubSGD iter. 305/499: loss=7.749650825956715, w0=72.80000000000014, w1=16.063274997660848\n",
      "SubSGD iter. 306/499: loss=82.59398230232655, w0=72.10000000000014, w1=16.183166811149178\n",
      "SubSGD iter. 307/499: loss=51.46102754647724, w0=72.80000000000014, w1=15.801040826598843\n",
      "SubSGD iter. 308/499: loss=3.1683264777259845, w0=73.50000000000014, w1=16.447188059986065\n",
      "SubSGD iter. 309/499: loss=30.599788524338155, w0=74.20000000000014, w1=16.09725012850575\n",
      "SubSGD iter. 310/499: loss=35.79254908674101, w0=73.50000000000014, w1=15.673708875451734\n",
      "SubSGD iter. 311/499: loss=75.29576843379597, w0=72.80000000000014, w1=15.61739926040643\n",
      "SubSGD iter. 312/499: loss=1.9705120943884522, w0=72.10000000000014, w1=15.352614151215661\n",
      "SubSGD iter. 313/499: loss=28.08919700098088, w0=72.80000000000014, w1=15.618097853439892\n",
      "SubSGD iter. 314/499: loss=10.55200832100686, w0=73.50000000000014, w1=16.33626117747108\n",
      "SubSGD iter. 315/499: loss=0.28292789903789434, w0=74.20000000000014, w1=17.131430902588427\n",
      "SubSGD iter. 316/499: loss=47.33045614086753, w0=73.50000000000014, w1=17.416605397137722\n",
      "SubSGD iter. 317/499: loss=24.719074604881502, w0=72.80000000000014, w1=17.23825327575791\n",
      "SubSGD iter. 318/499: loss=7.321591549148515, w0=73.50000000000014, w1=17.253560942470045\n",
      "SubSGD iter. 319/499: loss=0.6281367978349783, w0=72.80000000000014, w1=16.909848321286656\n",
      "SubSGD iter. 320/499: loss=12.345611570210707, w0=72.10000000000014, w1=17.295132461614784\n",
      "SubSGD iter. 321/499: loss=14.59871407803713, w0=72.80000000000014, w1=17.848338377690897\n",
      "SubSGD iter. 322/499: loss=34.321571505477436, w0=73.50000000000014, w1=16.99449210726563\n",
      "SubSGD iter. 323/499: loss=76.60522875494189, w0=72.80000000000014, w1=16.938182492220324\n",
      "SubSGD iter. 324/499: loss=12.270440383280935, w0=72.10000000000014, w1=15.854307095529023\n",
      "SubSGD iter. 325/499: loss=1.371398531108023, w0=72.80000000000014, w1=16.6876446780886\n",
      "SubSGD iter. 326/499: loss=0.09189546016927655, w0=72.10000000000014, w1=17.118655362837213\n",
      "SubSGD iter. 327/499: loss=12.234159773926189, w0=72.80000000000014, w1=17.28410815476984\n",
      "SubSGD iter. 328/499: loss=1.3530543885012072, w0=72.10000000000014, w1=15.918738702106229\n",
      "SubSGD iter. 329/499: loss=14.849886407694937, w0=72.80000000000014, w1=16.442919253557946\n",
      "SubSGD iter. 330/499: loss=85.3161499099273, w0=72.10000000000014, w1=16.456674449533438\n",
      "SubSGD iter. 331/499: loss=0.35475532807379906, w0=71.40000000000013, w1=16.450246568655093\n",
      "SubSGD iter. 332/499: loss=47.39718116706256, w0=72.10000000000014, w1=15.925613643943354\n",
      "SubSGD iter. 333/499: loss=0.1609888135760125, w0=72.80000000000014, w1=16.539528057320936\n",
      "SubSGD iter. 334/499: loss=38.16981140017088, w0=73.50000000000014, w1=15.502013863507395\n",
      "SubSGD iter. 335/499: loss=0.6623944161449696, w0=74.20000000000014, w1=16.620324084118877\n",
      "SubSGD iter. 336/499: loss=22.507631971673444, w0=74.90000000000015, w1=16.379344169452228\n",
      "SubSGD iter. 337/499: loss=8.393832608717503, w0=74.20000000000014, w1=15.633358515864831\n",
      "SubSGD iter. 338/499: loss=3.6613138525739704, w0=73.50000000000014, w1=16.759290929366003\n",
      "SubSGD iter. 339/499: loss=4.858275626299148, w0=72.80000000000014, w1=16.494505820175235\n",
      "SubSGD iter. 340/499: loss=0.11267183893953438, w0=72.10000000000014, w1=15.615333507944428\n",
      "SubSGD iter. 341/499: loss=54.97596898120635, w0=72.80000000000014, w1=15.859646231653562\n",
      "SubSGD iter. 342/499: loss=3.3484806987222, w0=73.50000000000014, w1=16.7158682841581\n",
      "SubSGD iter. 343/499: loss=0.49638118366018336, w0=72.80000000000014, w1=16.605568250697306\n",
      "SubSGD iter. 344/499: loss=0.26565013153034983, w0=72.10000000000014, w1=15.991653837319724\n",
      "SubSGD iter. 345/499: loss=11.295363576641963, w0=71.40000000000013, w1=16.336830925044723\n",
      "SubSGD iter. 346/499: loss=7.692152279971478, w0=72.10000000000014, w1=15.733064855078208\n",
      "SubSGD iter. 347/499: loss=22.59282496571853, w0=72.80000000000014, w1=14.37910796104498\n",
      "SubSGD iter. 348/499: loss=20.730672042762293, w0=72.10000000000014, w1=14.180347095226455\n",
      "SubSGD iter. 349/499: loss=12.940295141412081, w0=71.40000000000013, w1=14.462894914312681\n",
      "SubSGD iter. 350/499: loss=76.26219770366744, w0=72.10000000000014, w1=14.810861960703095\n",
      "SubSGD iter. 351/499: loss=4.705812247644598, w0=71.40000000000013, w1=15.544976283704084\n",
      "SubSGD iter. 352/499: loss=76.79035798956171, w0=72.10000000000014, w1=14.925835128289702\n",
      "SubSGD iter. 353/499: loss=14.932258308758351, w0=72.80000000000014, w1=15.091287920222328\n",
      "SubSGD iter. 354/499: loss=17.264419671944427, w0=72.10000000000014, w1=15.649411623971368\n",
      "SubSGD iter. 355/499: loss=18.16854851805472, w0=72.80000000000014, w1=15.675784274596188\n",
      "SubSGD iter. 356/499: loss=35.901958181145154, w0=72.10000000000014, w1=14.728872012853758\n",
      "SubSGD iter. 357/499: loss=12.289319838574263, w0=71.40000000000013, w1=15.264391695679963\n",
      "SubSGD iter. 358/499: loss=17.30891524649293, w0=72.10000000000014, w1=15.996356289187599\n",
      "SubSGD iter. 359/499: loss=0.1277084991155541, w0=72.80000000000014, w1=16.61027070256518\n",
      "SubSGD iter. 360/499: loss=25.010650550693057, w0=72.10000000000014, w1=16.411509836746657\n",
      "SubSGD iter. 361/499: loss=0.4368664233565275, w0=71.40000000000013, w1=16.851198241831842\n",
      "SubSGD iter. 362/499: loss=3.850334148032735, w0=72.10000000000014, w1=17.70742029433638\n",
      "SubSGD iter. 363/499: loss=1.7685933311376998, w0=72.80000000000014, w1=18.33969472281807\n",
      "SubSGD iter. 364/499: loss=0.050337043069831985, w0=72.10000000000014, w1=18.690031656186463\n",
      "SubSGD iter. 365/499: loss=0.00428307989468854, w0=72.80000000000014, w1=18.800331689647255\n",
      "SubSGD iter. 366/499: loss=39.321647577298265, w0=73.50000000000014, w1=18.404355446425424\n",
      "SubSGD iter. 367/499: loss=3.0038071769638743, w0=74.20000000000014, w1=17.278423032924252\n",
      "SubSGD iter. 368/499: loss=0.1499124057415154, w0=73.50000000000014, w1=16.422200980419714\n",
      "SubSGD iter. 369/499: loss=43.65136282861813, w0=72.80000000000014, w1=16.161488759037848\n",
      "SubSGD iter. 370/499: loss=15.027109800372443, w0=72.10000000000014, w1=16.78427516585814\n",
      "SubSGD iter. 371/499: loss=52.78369700472295, w0=72.80000000000014, w1=16.38481739347156\n",
      "SubSGD iter. 372/499: loss=25.810985994526256, w0=72.10000000000014, w1=16.862865595897684\n",
      "SubSGD iter. 373/499: loss=1.6019415594928448, w0=71.40000000000013, w1=16.128589852405884\n",
      "SubSGD iter. 374/499: loss=16.7028998537355, w0=70.70000000000013, w1=16.345846856585634\n",
      "SubSGD iter. 375/499: loss=9.396072411520954, w0=71.40000000000013, w1=16.595445319272812\n",
      "SubSGD iter. 376/499: loss=4.569818763970666, w0=70.70000000000013, w1=15.511569922581511\n",
      "SubSGD iter. 377/499: loss=43.372068218397914, w0=71.40000000000013, w1=14.47405572876797\n",
      "SubSGD iter. 378/499: loss=8.742463535352252, w0=70.70000000000013, w1=14.295703607388155\n",
      "SubSGD iter. 379/499: loss=10.155804064731813, w0=70.00000000000013, w1=13.348791345645726\n",
      "SubSGD iter. 380/499: loss=35.777865952240845, w0=70.70000000000013, w1=14.205013398150264\n",
      "SubSGD iter. 381/499: loss=6.036486339681258, w0=71.40000000000013, w1=14.73471437221238\n",
      "SubSGD iter. 382/499: loss=0.2602935150088214, w0=70.70000000000013, w1=15.085051305580771\n",
      "SubSGD iter. 383/499: loss=0.8891372590570022, w0=70.00000000000013, w1=14.730023828050946\n",
      "SubSGD iter. 384/499: loss=0.8989623719232784, w0=70.70000000000013, w1=13.786517344513825\n",
      "SubSGD iter. 385/499: loss=34.513337229032764, w0=71.40000000000013, w1=13.939411101628407\n",
      "SubSGD iter. 386/499: loss=6.392917248899955, w0=70.70000000000013, w1=14.552209272629819\n",
      "SubSGD iter. 387/499: loss=2.296955488244845, w0=71.40000000000013, w1=15.171342668574486\n",
      "SubSGD iter. 388/499: loss=25.875720847899867, w0=70.70000000000013, w1=15.603135246857907\n",
      "SubSGD iter. 389/499: loss=19.92045535544691, w0=71.40000000000013, w1=14.391712358931727\n",
      "SubSGD iter. 390/499: loss=3.4795803456952497, w0=70.70000000000013, w1=14.961672483467712\n",
      "SubSGD iter. 391/499: loss=29.619185195232177, w0=70.00000000000013, w1=15.642271661123795\n",
      "SubSGD iter. 392/499: loss=72.26507781774872, w0=70.70000000000013, w1=14.615339463531262\n",
      "SubSGD iter. 393/499: loss=3.582895901451524, w0=70.00000000000013, w1=13.958156760336276\n",
      "SubSGD iter. 394/499: loss=8.490173446048614, w0=70.70000000000013, w1=14.160593650377276\n",
      "SubSGD iter. 395/499: loss=0.6925258380541928, w0=71.40000000000013, w1=13.360762916314567\n",
      "SubSGD iter. 396/499: loss=0.18516414581269142, w0=72.10000000000014, w1=13.493086442668405\n",
      "SubSGD iter. 397/499: loss=9.97762747354348, w0=72.80000000000014, w1=14.326424025227983\n",
      "SubSGD iter. 398/499: loss=0.8139047259214542, w0=72.10000000000014, w1=13.734106063959805\n",
      "SubSGD iter. 399/499: loss=0.038499615449532475, w0=72.80000000000014, w1=13.623931947079065\n",
      "SubSGD iter. 400/499: loss=86.04127403230999, w0=72.10000000000014, w1=13.637687143054555\n",
      "SubSGD iter. 401/499: loss=72.72522553954161, w0=72.80000000000014, w1=13.985654189444968\n",
      "SubSGD iter. 402/499: loss=0.0002480917578540518, w0=72.10000000000014, w1=13.933493843915258\n",
      "SubSGD iter. 403/499: loss=3.0762261427742463, w0=72.80000000000014, w1=14.658514033996061\n",
      "SubSGD iter. 404/499: loss=52.1088190653298, w0=73.50000000000014, w1=14.039372878581679\n",
      "SubSGD iter. 405/499: loss=14.987400045131754, w0=74.20000000000014, w1=13.643396635359846\n",
      "SubSGD iter. 406/499: loss=0.9477363865614176, w0=73.50000000000014, w1=14.620194114301764\n",
      "SubSGD iter. 407/499: loss=82.17905628091414, w0=74.20000000000014, w1=15.745324074432071\n",
      "SubSGD iter. 408/499: loss=5.826429928789545, w0=74.90000000000015, w1=15.172313991417449\n",
      "SubSGD iter. 409/499: loss=1.815126714142501, w0=75.60000000000015, w1=15.36883407419595\n",
      "SubSGD iter. 410/499: loss=12.6896224217819, w0=74.90000000000015, w1=14.76430196834179\n",
      "SubSGD iter. 411/499: loss=33.63863403948969, w0=75.60000000000015, w1=14.145160812927408\n",
      "SubSGD iter. 412/499: loss=62.690382873700926, w0=76.30000000000015, w1=14.489629059797876\n",
      "SubSGD iter. 413/499: loss=0.9356379317337061, w0=77.00000000000016, w1=14.655081851730502\n",
      "SubSGD iter. 414/499: loss=21.710114525569942, w0=77.70000000000016, w1=15.835886552430399\n",
      "SubSGD iter. 415/499: loss=60.47907175679957, w0=77.00000000000016, w1=16.34438767017023\n",
      "SubSGD iter. 416/499: loss=36.93978915920075, w0=76.30000000000015, w1=14.981636274778484\n",
      "SubSGD iter. 417/499: loss=27.665212731857597, w0=75.60000000000015, w1=15.685141193169347\n",
      "SubSGD iter. 418/499: loss=1.618463094360697, w0=76.30000000000015, w1=15.34877823549327\n",
      "SubSGD iter. 419/499: loss=0.024748844608947586, w0=77.00000000000016, w1=15.77629532071069\n",
      "SubSGD iter. 420/499: loss=32.65213235633811, w0=76.30000000000015, w1=16.281313052535012\n",
      "SubSGD iter. 421/499: loss=1.3016572311921122, w0=75.60000000000015, w1=15.831133306328718\n",
      "SubSGD iter. 422/499: loss=4.3682845699687185, w0=76.30000000000015, w1=15.868420617946589\n",
      "SubSGD iter. 423/499: loss=0.6857020449258768, w0=77.00000000000016, w1=14.656997730020409\n",
      "SubSGD iter. 424/499: loss=1.1168824126405583, w0=77.70000000000016, w1=15.181178281472127\n",
      "SubSGD iter. 425/499: loss=4.7563921668300635, w0=77.00000000000016, w1=16.36518048186602\n",
      "SubSGD iter. 426/499: loss=35.18088860365422, w0=76.30000000000015, w1=16.44599478735473\n",
      "SubSGD iter. 427/499: loss=16.81205216199182, w0=75.60000000000015, w1=16.181209678163963\n",
      "SubSGD iter. 428/499: loss=49.63510410080445, w0=74.90000000000015, w1=16.398466682343713\n",
      "SubSGD iter. 429/499: loss=4.0382320863993, w0=75.60000000000015, w1=16.062103724667637\n",
      "SubSGD iter. 430/499: loss=23.759245825749147, w0=74.90000000000015, w1=15.361169727232884\n",
      "SubSGD iter. 431/499: loss=51.00102705077149, w0=74.20000000000014, w1=15.641098719669348\n",
      "SubSGD iter. 432/499: loss=5.760181280371147, w0=73.50000000000014, w1=15.37631361047858\n",
      "SubSGD iter. 433/499: loss=3.126021908779628, w0=72.80000000000014, w1=15.72665054384697\n",
      "SubSGD iter. 434/499: loss=3.60482866207495, w0=72.10000000000014, w1=16.253607579615817\n",
      "SubSGD iter. 435/499: loss=4.340535862840535, w0=72.80000000000014, w1=15.900491828048503\n",
      "SubSGD iter. 436/499: loss=0.8489187470423144, w0=72.10000000000014, w1=15.611994563491088\n",
      "SubSGD iter. 437/499: loss=7.090278348297788, w0=72.80000000000014, w1=14.933647567516545\n",
      "SubSGD iter. 438/499: loss=5.115820353923418, w0=72.10000000000014, w1=15.32908435945955\n",
      "SubSGD iter. 439/499: loss=12.24171508082954, w0=72.80000000000014, w1=16.208332325355723\n",
      "SubSGD iter. 440/499: loss=12.94084272640052, w0=73.50000000000014, w1=17.22101066670849\n",
      "SubSGD iter. 441/499: loss=2.069337517648561, w0=74.20000000000014, w1=16.867894915141175\n",
      "SubSGD iter. 442/499: loss=20.42958485925109, w0=73.50000000000014, w1=17.253179055469303\n",
      "SubSGD iter. 443/499: loss=9.911863071442456, w0=72.80000000000014, w1=16.660861094201124\n",
      "SubSGD iter. 444/499: loss=1.1922761052748942, w0=72.10000000000014, w1=16.65443321332278\n",
      "SubSGD iter. 445/499: loss=0.05860614316501376, w0=71.40000000000013, w1=16.12637739781213\n",
      "SubSGD iter. 446/499: loss=0.02353154584099143, w0=72.10000000000014, w1=16.887734348431202\n",
      "SubSGD iter. 447/499: loss=5.99345784707012, w0=72.80000000000014, w1=17.511222470717378\n",
      "SubSGD iter. 448/499: loss=0.006906492922990667, w0=73.50000000000014, w1=18.306392195834725\n",
      "SubSGD iter. 449/499: loss=16.99502566888848, w0=74.20000000000014, w1=17.329594716892807\n",
      "SubSGD iter. 450/499: loss=37.64361716699281, w0=73.50000000000014, w1=17.130833851074282\n",
      "SubSGD iter. 451/499: loss=0.07437242680838105, w0=74.20000000000014, w1=16.041038828001064\n",
      "SubSGD iter. 452/499: loss=62.24158359357789, w0=73.50000000000014, w1=15.082903737099256\n",
      "SubSGD iter. 453/499: loss=16.945621581427687, w0=72.80000000000014, w1=15.634875169036935\n",
      "SubSGD iter. 454/499: loss=4.12592463228563, w0=73.50000000000014, w1=16.28693206647939\n",
      "SubSGD iter. 455/499: loss=3.824057374109629, w0=72.80000000000014, w1=17.095045807521323\n",
      "SubSGD iter. 456/499: loss=0.5460666990383347, w0=73.50000000000014, w1=15.969113394020152\n",
      "SubSGD iter. 457/499: loss=1.763641814290118, w0=72.80000000000014, w1=16.51212985538525\n",
      "SubSGD iter. 458/499: loss=6.9667535025852985, w0=72.10000000000014, w1=16.176901800081996\n",
      "SubSGD iter. 459/499: loss=81.09249030984334, w0=72.80000000000014, w1=17.416218101059997\n",
      "SubSGD iter. 460/499: loss=9.941037335589522, w0=72.10000000000014, w1=17.96338040329387\n",
      "SubSGD iter. 461/499: loss=23.441787713428486, w0=71.40000000000013, w1=16.60062900790212\n",
      "SubSGD iter. 462/499: loss=7.5953816153766485e-06, w0=70.70000000000013, w1=16.46830548154828\n",
      "SubSGD iter. 463/499: loss=0.12546946920350965, w0=71.40000000000013, w1=16.028617076463096\n",
      "SubSGD iter. 464/499: loss=0.5104583649870726, w0=72.10000000000014, w1=16.7536372665439\n",
      "SubSGD iter. 465/499: loss=0.01354359004091936, w0=72.80000000000014, w1=16.383369176015105\n",
      "SubSGD iter. 466/499: loss=1.895880220085572, w0=73.50000000000014, w1=17.239591228519643\n",
      "SubSGD iter. 467/499: loss=24.40297477676287, w0=72.80000000000014, w1=17.06123910713983\n",
      "SubSGD iter. 468/499: loss=49.24671276225924, w0=73.50000000000014, w1=16.679113122589495\n",
      "SubSGD iter. 469/499: loss=38.848483633312945, w0=74.20000000000014, w1=16.279655350202916\n",
      "SubSGD iter. 470/499: loss=50.766823993390375, w0=73.50000000000014, w1=16.56482984475221\n",
      "SubSGD iter. 471/499: loss=0.7508104950480082, w0=74.20000000000014, w1=16.198909114021813\n",
      "SubSGD iter. 472/499: loss=1.3039778000077038, w0=73.50000000000014, w1=16.08860908056102\n",
      "SubSGD iter. 473/499: loss=0.5341189437650228, w0=74.20000000000014, w1=16.883778805678368\n",
      "SubSGD iter. 474/499: loss=14.31414095233995, w0=73.50000000000014, w1=16.00404867584589\n",
      "SubSGD iter. 475/499: loss=14.483709612616847, w0=72.80000000000014, w1=16.539568358672096\n",
      "SubSGD iter. 476/499: loss=29.052021329334917, w0=72.10000000000014, w1=15.371237558154627\n",
      "SubSGD iter. 477/499: loss=4.159135039416192, w0=72.80000000000014, w1=14.60041449208644\n",
      "SubSGD iter. 478/499: loss=1.8058737321689562, w0=73.50000000000014, w1=14.473400046858414\n",
      "SubSGD iter. 479/499: loss=13.148663605435468, w0=74.20000000000014, w1=14.510687358476284\n",
      "SubSGD iter. 480/499: loss=19.27087920362049, w0=73.50000000000014, w1=14.933926783248799\n",
      "SubSGD iter. 481/499: loss=4.45778966205713, w0=74.20000000000014, w1=15.566201211730489\n",
      "SubSGD iter. 482/499: loss=3.743490816402851, w0=73.50000000000014, w1=15.523874655126997\n",
      "SubSGD iter. 483/499: loss=8.378326204127081, w0=72.80000000000014, w1=16.227379573517858\n",
      "SubSGD iter. 484/499: loss=2.6001263521570217, w0=72.10000000000014, w1=17.06740714497767\n",
      "SubSGD iter. 485/499: loss=33.535509948823474, w0=72.80000000000014, w1=17.18122747179198\n",
      "SubSGD iter. 486/499: loss=68.36128423915557, w0=72.10000000000014, w1=17.124917856746677\n",
      "SubSGD iter. 487/499: loss=3.952063557756761, w0=71.40000000000013, w1=17.676889288684357\n",
      "SubSGD iter. 488/499: loss=50.07112010291047, w0=72.10000000000014, w1=18.802019248814666\n",
      "SubSGD iter. 489/499: loss=31.376737589372503, w0=72.80000000000014, w1=17.825221769872748\n",
      "SubSGD iter. 490/499: loss=9.877771260851318, w0=72.10000000000014, w1=17.194056429877897\n",
      "SubSGD iter. 491/499: loss=25.966809100831615, w0=72.80000000000014, w1=18.37486113057779\n",
      "SubSGD iter. 492/499: loss=8.361675594462323, w0=72.10000000000014, w1=17.53367096235315\n",
      "SubSGD iter. 493/499: loss=0.24134036768870654, w0=71.40000000000013, w1=16.41536074174167\n",
      "SubSGD iter. 494/499: loss=14.062257636491989, w0=72.10000000000014, w1=15.231358541347777\n",
      "SubSGD iter. 495/499: loss=43.42412712110798, w0=72.80000000000014, w1=14.204426343755244\n",
      "SubSGD iter. 496/499: loss=37.618174829022735, w0=72.10000000000014, w1=14.682474546181368\n",
      "SubSGD iter. 497/499: loss=1.3739669245456145, w0=72.80000000000014, w1=15.29638895955895\n",
      "SubSGD iter. 498/499: loss=7.173695044727261, w0=72.10000000000014, w1=15.909187130560362\n",
      "SubSGD iter. 499/499: loss=0.9738137751561212, w0=71.40000000000013, w1=15.644402021369594\n",
      "SubSGD: execution time=0.041 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93552bbc3b64dcca1942059da99a15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
